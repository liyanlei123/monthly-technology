Consul与Eureka的不同点：
	1. 最大的区别是Eureka保证AP，Consul为CP；
	2. Consul强一致性(C)带来的是：服务注册相比Eureka会稍慢一些。因为Consul的Raft协议要求必须过半的节点都写入成功才认为注册成功。Leader挂掉时，重新选举期间整个Consul不可用。保证了强一致性但牺牲了可用性；
	3. Eureka保证高可用(A)和最终一致性：服务注册相对要快，因为不需要等注册信息replicate到其他节点，也不保证注册信息是否replicate成功。当数据出现不一致时，虽然A，B上的注册信息不完全相同，但每个Eureka节点依然能够正常对外提供服务，这会出现查询服务信息如果请求A查不到，但请求B就能查询到。如此保证了可用性但牺牲了一致性；
	4. 服务的健康检查：Eureka使用时需要显式配置健康检查支持；ZK, Etcd则在失去了和服务进程的连接情况下不健康，而Consul相对更为详细，必然内存是否已经使用了90%，文件系统的空间是否快不足了。
	5. 多数据中心支持：Consul通过WAN的Gossip协议，完成跨数据中心的同步；而且其他的产品则需要额外的开发工作来失效；
	6. KV存储服务：除了Eureka，其他几款都能够对外支持KV存储服务，所以其他几款都追求高一致性的重要原因。而提供存储服务，也能够较好的转化为动态配置服务。

SSL是Secure Sockets Layer，即安全套接层协议，是为网络通信提供安全及数据完整性的一种安全协议。
HTTPS为了兼顾安全与效率，同时使用了对称加密和非对称加密。数据是被对称加密传输的，对称加密过程需要客户端的一个密钥，为了确保能把该密钥安全传输到服务器端，采用非对称加密对该密钥进行加密。总的来说，对数据进行对称加密，对称加密所用的密钥是通过非对称加密传输。

Https协议考虑的几个问题：
	1. 兼容性；
	2. 可扩展性；
	3. 保密性(防泄密)；
	4. 完整性(防篡改)；
	5. 真实性(防假冒)；
	6. 性能；

Http版本的发展历史：
版本		产生时间			内容													发展现状
Http/0.9	1991年	不涉及数据包传输，规定客户端和服务器之间通信格式，只能Get请求		没有作为正式标准
Http/1.0	1996年	传输内容格式不限制，增加put,patch,head, options,delete命令			正式作为标准
Http/1.1	1997年	持久连接(长连接),节约带宽,Host域,管道机制,分块传输编码				2015年前最广泛
Http/2.0	2015年		多路复用，服务器推送，头信息压缩，二进制协议等					逐渐覆盖市场

针对Http的无状态的解决策略：
	1. 通过Cookie/Session技术；
	2. Http/1.1持久连接(Http keep-alive)方法，只要任意一端没有明确提出断开连接，则保持TCP连接状态，在请求首部字段中的Connection: keep-alive即为表明使用了持久连接。

为什么需要三次握手呢？为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。比如：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段，但是server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求，于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了，由于client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据，但server却以为新的运输连接已经建立，并一直等待client发来数据。所以没有采用“三次握手”，这种情况下server的很多资源就白白浪费掉了。

为什么需要四次挥手呢？TCP是全双工模式，当client发出FIN报文段时，只是表示client已经没有数据要发送了，client告诉server，它的数据已经全部发送完毕了；但是，这个时候client还是可以接受来server的数据；当server返回ACK报文段时，表示它已经知道client没有数据发送了，但是server还是可以发送数据到client的；当server也发送了FIN报文段时，这个时候就表示server也没有数据要发送了，就会告诉client，我也没有数据要发送了，如果收到client确认报文段，之后彼此就会愉快的中断这次TCP连接。

----------------------------------------------------
Https建立的过程：
	1. client向server发送请求https://baidu.com，然后连接到server的443端口，发送的信息主要是随机值1和客户端支持的加密算法。
	2. server接收到信息之后给client响应握手信息，包括随机值2和匹配好的协商加密算法，加密算法一定是client发送给server加密算法的子集。
	3. 随即server给client发送第二个响应报文是数字证书。服务端必须要有一套数字证书，可以自己制作，也可以向组织申请。区别就是自己颁发的证书需要客户端验证通过，才可以继续访问，而使用受信任的公司申请的证书则不会弹出提示页面，这套证书其实就是一对公钥和私钥。传送证书，这个证书其实就是公钥，只是包含了很多信息，如证书的颁发机构，过期时间、服务端的公钥，第三方证书认证机构(CA)的签名，服务端的域名信息等内容。
	4. 客户端解析证书，这部分工作是由客户端的TLS来完成的，首先会验证公钥是否有效，比如颁发机构，过期时间等等，如果发现异常，则会弹出一个警告框，提示证书存在问题。如果证书没有问题，那么就生成一个随机值（预主秘钥）。
	5. 客户端认证证书通过之后，接下来是通过随机值1、随机值2和预主秘钥组装会话秘钥。然后通过证书的公钥加密会话秘钥。
	6. 传送加密信息，这部分传送的是用证书加密后的会话秘钥，目的就是让服务端使用秘钥解密得到随机值1、随机值2和预主秘钥。
	7. 服务端解密得到随机值1、随机值2和预主秘钥，然后组装会话秘钥，跟客户端会话秘钥相同。
	8. 客户端通过会话秘钥加密一条消息发送给服务端，主要验证服务端是否正常接受客户端加密的消息。
	9. 同样服务端也会通过会话秘钥加密一条消息回传给客户端，如果客户端能够正常接收的话表明SSL层连接建立完成了。
----------------------------------------------------
Apache ServiceComb是业界第一个Apache微服务顶级项目，是一个开源微服务解决方案。

ServiceComb目前拥有三个主要子项目：
	1. Java chassis:开箱即用JAVA语言微服务SDK，含服务契约、编程模型、运行模式与通信模型四个部分，具备负载均衡、容错熔断、限流降级、调用链追踪等全面微服务治理能力，服务治理能力与业务逻辑隔离。
	2. Service Center：服务注册中心；基于Etcd的高性能、高可用、无状态的Golang版分布式服务注册与发现中心，可实时服务实例注册、实时服务实例推送和服务间契约测试等；
	3. Saga:分布式事务解决方案；ServiceComb Saga提供了分布式事务最终一致性解决方案，用户只需要通过注解方式定义事务的执行方法以及撤销方法，Saga框架会自动保证分布式事务执行的最终一致性。

--------------------------------------------------------------------------------
ConcurrentHashMap中类似于LongAdder的机制：

public class ConcurrentHashMap<K, V> extends AbstractMap<K, V>
	implements ConcurrentMap<K, V>, Serializable {
	...
	
	/* Base counter value, used mainly when there is no contention,
		but also as a fallback during table initialization races.
		Updated via CAS.
	*/
	private transient volatile long baseCount;
	
	/* Table initialization and resizing control. When negative, the table is being 
		initialized or resized: -1 for initialization, else -(1 + the number of active 
		resizing threads). Otherwise, when the table is null, holds the initial table size to use upon
		creation, or 0 for default. After initialization, holds the next element count value upon 
		which to resize the table.
	*/
	private transient volatile int sizeCtl;
	
	/* Spinlock (locked via CAS) used when resizing and/or creating CounterCells.
	*/
	private transient volatile int cellsBusy;
	
	/* Table of counter cells. When non-null, size is a power of 2.
	*/
	private transient volatile CounterCell[] counterCells;
	...
	
	/* -------------- Counter support ------------------*/
	/*
	/* A padded cell for distributing counts. Adapted from LongAdder and Striped64.
		See their internal docs for explanation.
	*/
	@sun.misc.Contended 
	static final class CounterCell {
		volatile long value;
		CounterCell(long x) { value = x;}
	}
	
	final long sumCount() {
		CounterCell[] as = counterCells;
		CounterCell a;
		long sum = baseCount;
		if (as != null) {
			for (int i = 0;i < as.length; ++i) {
				if ((a = as[i]) != null) {
					sum += a.value;
				}
			}
		}
		return sum;
	}
	
	// See LongAdder version for explanation
	private final void fullAddCount(long x, boolean wasUncontended) {
		int h;
		if ((h = ThreadLocalRandom.getProbe()) == 0) {
			ThreadLocalRandom.localInit();   // force initialization
			h = ThreadLocalRandom.getProbe();
			wasUncontended = true;
		}
		
		boolean collide = false;   // True if last slot nonempty
		for (;;) {
			CounterCell[] as;
			CounterCell a;
			int n;
			long v;
			
			if ((as = counterCells) != null && (n = as.length) > 0) {
				if ((a = as[(n - 1) & h]) == null) {
					if (cellsBusy == 0) {   // Try to attach new Cell
						CounterCell r = new CounterCell(x);   //Optimistic create 
						if (cellsBusy == 0 && U.compareAndSwapInt(this, CELLBUSY, 0, 1) {
							boolean created = false;
							try {   // Recheck under lock
								CounterCell[] rs;
								int m, j;
								if ((rs = counterCells) != null && 
									(m = rs.length) > 0 && 
									rs[j = (m - 1) & h] == null) {
									rs[j] = r;
									created = true;
								}
							} finally {
								cellsBusy = 0;
							}
							if (created)
								break;
							continue;
						}
					}
					collide = false;
				} else if (!wasUncontended) {   //CAS already known to fail
					wasUncontended = true;   // Continue after rehash
				} else if (U.compareAndSwapLong(a, CELLVALE, v = a.value, v + x)) {
					break;
				} else if (counterCells != as || n > NCPU) {
					collide = false;   // At max size or stale
				} else if (!collide) {
					collide = true;
				} else if (cellsBusy == 0 && U.compareAndSwapInt(this, CELLBUSY, 0, 1)) {
					try {
						if (counterCells == as) {   // Expand table unless stale 
							CounterCell[] rs = new CounterCell[n << 1];
							for (int i = 0;i < n;i ++)
								rs[i] = as[i];
							counterCells = rs;
						}
					} finally {
						cellsBusy = 0;
					}
					collide = false;
					continue;   // Retry with expanded table
				}
				h = ThreadLocalRandom.advanceProbe(h);
			} else if (cellsBusy == 0 && counterCells == as 
					&& U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) {
				boolean init = false;
				try {   // Initialize table
					if (counterCells == as) {
						CounterCell[] rs = new CounterCell[2];
						rs[h & 1] = new CounterCell(x);
						counterCells = rs;
						init = true;
					}
				} finally {
					cellsBusy = 0;
				}
				if (init) {
					break;
				}
			} else if (U.compareAndSwapLong(this, BASECOUNT, v = baseCount, v+x)) {
				break;   //Fall back on using base
			}
		}
	}
	...
}

ConcurrentHashMap中@sun.misc.Contended的应用:
    /* ---------------- Counter support -------------- */

    /**
     * A padded cell for distributing counts.  Adapted from LongAdder
     * and Striped64.  See their internal docs for explanation.
     */
    @sun.misc.Contended static final class CounterCell {
        volatile long value;
        CounterCell(long x) { value = x; }
    }
--------------------------------------------------------------------------------
从简单的生产者消费者模式设计到如何高效健壮实现：
	1. 多生产者的竞争: 参考LongAdder的实现
	2. 模拟偏向锁，每个子容器的线程占用，升级到重量级锁，然后适当时机增加子容器数目；
	3. 多消费者
	4. 提供带超时机制的poll, peek, offer;
	5. Condition notEmpty = lock.newCondition();
		Condition notFull = lock.newCondition();
	6. Object.notifyAll(), Object.wait()
	7. try*类似接口
	8. 分布式的解决方案: MQ

notify/notifyAll()执行后，并不立即释放锁，而是等到执行完临界区中代码后，再释放。所以在实际编程中，应该尽量在线程调用notify/notifyAll()后，立即退出临界区。即不要在notify/notifyAll()后面再写一些耗时的代码。

Consul的四大核心特性：
	1. 服务发现：可以方便的实现服务注册通过DNS或者HTTP应用程序可以很容易的找到它所依赖的服务；
	2. KV存储：使用Key/Value进行数据存储；
	3. 多数据中心：Consul支持开箱即用的多数据中心。这意味着用户不需要担心建立额外的抽象层让业务扩展到多个区域；
	4. 健康检查：可以对指定服务进行健康检查例如Response Status是否为200避免将流量转发到不健康的服务上。

由程序产生的地址称为虚拟地址，它们构成了一个虚拟地址空间。在没有虚拟内存的计算机上，系统直接把虚拟地址送到内存总线上，读写操作使用具有相同地址的物理内存地址；而在使用虚拟内存的情况下，虚拟地址不是被直接送到内存总线上，而是被送到内存管理单元(Memory Management Unit, MMU)， MMU把虚拟地址映射为物理内存地址。
虚拟地址空间按照固定大小划分为称为页面Page的若干单元。在物理内存中对应的单元称为页框。页面和页框的大小通常是一样的。实际系统中的页面大小从512字节到1GB.

虚拟地址被分成虚拟页号（高地址）和偏移量（低地址）两部分。不同的划分对应了不同的页面大小。
    虚拟页号可作为页表的索引，以找到该虚拟页面对应的页表项。由页表项可以找到对应的页框。然后把页框号拼接到偏移量的高位端，以替换调虚拟页号，形成送往内存的物理地址。
    页表的目的是把虚拟页面映射为页框，把虚拟地址中的虚拟页面域替换成页框域，从而形成物理地址（本篇博客讨论的情况均不涉及虚拟机，每个虚拟机都需要有自己的虚拟内存，因此页表组织变得很复杂，包括影子页表和嵌套页表）。

--------------转换检测缓冲区-------------------
       大多数程序总是对少量的页面进行多次的访问，只有很少的页表项会被反复读取，而其他大的页表项很少被访问。利用这种特性有一种解决方案：为计算机设计一个小型的硬件设备，将虚拟地址直接映射到物理地址，而不必再访问页表。这种设备称为转换检测缓冲区（Translation Lookaside Buffers，TLB），有时又称为相联存储器或快表。它通常在MMU中，包含少量的表项，在实际中很少会超过256个。每个表项记录了一个页面的相关信息，包括虚拟页号、页面的修改位、保护码和该页所对应的物理页框，还有另外一位用来记录这个表项是否有效（即是否在使用）。
       TLB的工作过程：将一个虚拟地址放入MMU中进行转换时，硬件首先通过将该虚拟页号与TLB中所有表项同时（并行）进行匹配，判断虚拟页面是否在其中。如果发现在，并且不违反保护码，则将页框号直接从TLB中取出而不必再访问页表。如果违反了保护码，则会产生一个保护错误，就像对页表进行非法操作一样。如果虚拟页号不在TLB中，此时就会去进行正常的页表查询。接着从TLB中淘汰掉一个表项，然后用找到的页表项代替它。当一个表项被清除除TLB时，将修改位复制到内存中的页表项，而除了访问位，其他的值不变。当页表项中从页表中装入TLB中时，所有的值都来自内存。
---------------------------------
Vert.x最大的特点就在于异步(底层基于Netty)，通过事件循环(EventLoop)来调起存储在异步队列(CallBackQueue)中的任务，大大降低了传统阻塞模型中线程对于操作系统的开销。因此相比传统的阻塞模型，异步模型能够很大程度的提高系统的并发量。
Vert.x除了异步之外，还提供了非常多的技术，比如EventBus，通过EventBus可以非常简单的实现分布式消息，进而为分布式系统调用、微服务奠定基础。除此之外，还提供了对多种客户端的支持，比如Redis、RabbitMQ、Kafka等等。
Vert.x异步也带来了编码上的复杂性，想要编写优美的异步代码，就需要对lambda表达式、函数式编程、Reactive等技术非常熟悉才行，否则很容易导致代码糟糕，完全没有可读性。另外，异步模型的性能调优、异常处理与同步模型有很大差。
Vert.x运行在JVM虚拟机上，支持多种编程语言，Vert.x是高度模块化的，同一个应用，可以选择多种编程语言同时开发。在Vert.x 2版本基于JDK7，没有lambda表达式，一般来讲使用javascript作为开发语言相对较多，到Vert.x3时代，因为JDK8的出现，Java已经作为Vert.x主流开发语言，而Vert.x也被更多开发者接受。

Vert.x可以做的事情：Java能做的，Vert.x都能做。
（1）Web开发，Vert.x封装了Web开发常用的组件，支持路由、Session管理、模板等，可以非常方便的进行Web开发。不需要容器！不需要容器！不需要容器！
（2）TCP/UDP开发，Vert.x底层基于Netty，提供了丰富的IO类库，支持多种网络应用开发。不需要处理底层细节（如拆包和粘包），注重业务代码编写。
（3）提供对WebSocket的支持，可以做网络聊天室，动态推送等。
（4）Event Bus（事件总线）是Vert.x的神经系统，通过Event Bus可以实现分布式消息，远程方法调用等等。正是因为Event Bus的存在，Vert.x可以非常便捷的开发微服务应用。
（5）支持主流的数据和消息的访问;redis mongodb rabbitmq kafka等
（6）分布式锁，分布式计数器，分布式map的支持
---------------------------------
根据一个项目，如果量级扩大1000倍，会怎么做？有哪些优化措施？高性能&高可用措施？
	1. 冷热数据分离；
	2. 冷数据提前做好归总汇集，按查询维度、指标做好汇总表；
	3. 将查询量大的热数据放在缓存中，并做好数据分片；每日对账清结算后，将增量数据更新到缓存；
	4. 分库分表：注意数据一致性，特别是主从库的延迟。通过缓存30分钟的数据来覆盖延迟时间差；
	5. 微服务的拆分，分布式处理；
	6. 动态扩容/缩容；
	7. 降级熔断保护系统不被压垮；
	8. 部分不可变数据的多级缓存：分布式缓存+本地缓存；
	9. 部分高并发逻辑，并且不要求实时处理的，进行异步处理，使用Kafka来做削峰填谷，避免压垮系统；
	10. 为了防止压垮别的系统，也会对部分高并发业务且不要求实时处理的，直接异步处理；
	11. 如果再有高并发请求：不直接落库DB，双写到分布式缓存和Kafka，从分布式缓存的从库慢慢写入数据库，用Kafka来进行兜底保障；
	12. 分库分表，读写分离；
	13. 合理的索引，合理的数据表结构；
	14. Java更加合理是算法和数据结构：LongAdder，CopyOnWriteArrayList, 分布式锁的合理使用，分布式事务的最终一致性，无锁化设计；
	15. 网络连接内部改为长连接，比如使用Netty；
	16. 性能测试，找出热点函数，进行优化；
	17. JVM相关的优化；
	18. 多数据中心部署；
	19. 部分请求的CDN
	20. 海量数据的查询、统计考虑用ElasticSearch来支持高并发；
	21. 
---------------------------------
ConcurrentHashMap最耗时的操作是扩容resize, 所以对扩容操作进行优化可以很大程度上提高性能，而这个优化手段就是让并发执行put操作的线程协助搬运bin中的Node，把数据项从老数组转移到新数组，从而加速resize操作。具体方案是：在执行put操作的线程中，第一个发现需要扩容的线程负责分配新数组、开始转移部分Node，每次处理一个bin；此后，其他发现有resize正在进行中的线程参与到转移Node工作；其他也在执行put操作但不参与转移工作的线程继续执行原来的put操作(先在原数组中找到bin，如果遇到FowardingNode，则在新数组中插入)；执行get操作的线程不参与转移工作，遇到FordwardingNode则到新数组查询。
具体怎么迁移：参与迁移的线程通过transferIndex字段声明自己要迁移哪些bin。同时，为了防止这些线程所迁移的bin有重叠的，迁移线程会在sizeCtl变量中保存一个stamp提供区分的作用。为了不影响正在对ConcurrentHashMap进行遍历操作的线程，迁移工作从最后一个bin开始(table.length - 1)，逐步往前处理，直到处理完第一个。每迁移完成一个bin或正在迁移当前bin，这里的位置就被放入一个FordwardingNode。因为迁移Node操作需要较长时间，FordwardingNode让其他执行put/get遍历操作的线程可以继续访问。

SSL: Secure Socket Layer 安全套接层
TLS: Transport Layer Security 传输层安全

notify/notifyAll信号丢失问题；执行等待的线程都需要一个等待条件，为了避免出现丢失的信号，仍然需要对条件变量进行while循环的判断。

关于等待通知机制的几点要求：
	1. 每当在等待一个条件时，一定要确保在条件变量变为真的时候才发出唤醒的通知；
	2. 在调用wait/notify/notifyAll方法时，必须首先获得锁；
	3. 每次调用完wait方法，获得锁就会自动释放；
	4. 调用notify时，JVM从等待队列中的一个线程进行唤醒；notifyAll将等待队列中的所有线程都唤醒；
	5. 只有同时满足两个条件才能使用notify:
		一是所有等待线程的类型都相同，这就是说，等待队列只与一个条件变量相关，并且所有的线程在唤醒后执行的都是相同的操作；
		二是单进单出，也就是说在条件变量的每个通知，要求只能最多唤醒一个线程。
	
假唤醒：假唤醒就是在没有线程调用notify或notifyAll方法的情况下被唤醒。为了防止假唤醒，保存的条件变量需要在while循环中进行检测，而不是在if表达式里。这样的一个while循环叫做自旋锁（校注：这种做法要慎重，目前的JVM实现自旋会消耗CPU，如果长时间不调用doNotify方法，doWait方法会一直自旋，CPU会消耗太大）。被唤醒的线程会自旋直到自旋锁(while循环)里的条件变为false。
-------------------------------------
Consul的机制，和其他注册中心的对比(ZK, Eureka)

主流注册中心产品的比对矩阵：
					Nacos						Eureka			Consul				CoreDNS		Zookeeper
一致性协议			CP+AP						AP				CP					-			CP
健康检查 			TCP/HTTP/MySQL/Client Beat	Client Beat		TCP/HTTP/gRPC/Cmd	-			Keep Alive
负载均衡策略		权重/metadata/Selector		Ribbon			Fabio				RoundRobin	-
雪崩保护			有							有 				无 					无 			无
自动注销实例		支持 						支持 			不支持 				不支持 		支持
访问协议 			HTTP/DNS					HTTP			HTTP/DNS 			DNS			TCP
监听支持			支持  						支持  			支持 				不支持 		支持 
多数据中心 			支持 						不支持 			支持 				不支持 		不支持
跨注册中心同步		支持   						支持 			支持 				不支持 		不支持
SpringCloud集成		支持 						支持 			支持 				不支持		支持 
Dubbo集成			支持						不支持 			不支持 				不支持   	支持
K8S集成				支持 						不支持 			支持 				支持 		不支持
-------------------------------------
一旦一个线程被唤醒，不能立刻就退出wait()的方法调用，直到调用notify()的线程退出了自己的同步块。换句话说：被唤醒的线程必须重新获得监视器对象的锁，才可以退出wait()的方法调用，因为wait方法调用运行在同步块里面。如果多个线程被notifyAll()唤醒，那么同一时刻将只有一个线程可以退出wait()方法，因为每个线程在退出wait()前必须获得监视器对象的锁。

丢失的信号: Missed Signals.
伪唤醒/假唤醒

RPC的主要功能目标是让构建分布式计算(应用)更容易，在提供强大的远程调用能力时不损失本地调用的语义简洁性。为实现该目标，RPC框架需提供一种透明调用机制让使用者不必显式的区分本地调用和远程调用。

RPC服务方通过RPCServer去导出(export)远程接口方法，而客户方通过RPCClient去引入(import)远程接口方法。客户方像调用本地方法一样调用远程接口方法，RPC框架提供接口的代理实现，实际的调用将委托给代理RPCProxy。代理封装调用信息并将调用转交给RPCInvoker去实际执行。在客户端的RPCInvoker通过连接器RPCConnector去维护与服务端的通道RPCChannel，并使用RPCProtocol执行协议编码(encode)并将编码后的请求消息通过通道发送给服务方。
RPC服务端接收器RPCAcceptor接收客户端的调用请求，同样使用RPCProtocol执行协议解码(decode)。解码后的调用信息传递给RPCProcessor去控制处理调用过程，最后再委托调用给RPCInvoker去实际执行并返回调用结果。

调用过程的控制需要考虑哪些因素，RPCProcessor需要提供什么样的调用控制服务呢？需要考虑几点：
	1. 效率提升：每个请求应该尽快被执行，因此不能每个请求来时再创建线程去执行，需要提供线程池服务；
	2. 资源隔离：当我们导出多个远程接口时，如何避免单一接口调用占据所有资源，而引发其他接口阻塞；
	3. 超时控制：当某个接口执行缓慢，而Client端已经超时放弃等待后，Server端的线程继续执行显得无意义；

Dubbo的RPC流程：服务引用、服务暴露、服务调用三个部分；
在Dubbo中有两个核心概念：
	1. Invoker:Dubbo的核心模型，其他模型都向他靠拢，或转换成它，它代表一个可执行体，可向他发起invoke调用；
	2. Protocol:是Invoker暴露和引用的主功能入口，它负责Invoker的生命周期；

Dubbo基于扩展点的自适应机制(SPI),会自动识别URL中的协议类型，并调用合适的Protocol实现类，默认用的是Dubbo协议，因此会调用DubboProtocol进行服务引用；
ProxyFactory同样是扩展点，默认使用了JavassitProxyFactory的实现。可以看到创建的代理，把对接口的调用交给了InvokerInvocationHandler这个类去处理。

Zookeeper和Consul保证的是CP，而Eureka则是AP，Nacos不仅支持CP也支持AP。

Eureka还有一种自我保护机制，如果在15分钟内超过85%的节点都没有正常的心跳，那么Eureka就认为客户端与注册中心出现了网络故障，此时会出现几种情况：
	1. Eureka不再从注册列表中移除因为长时间没收到心跳而应该过期的服务；
	2. Eureka仍然能够接收服务的注册和查询请求，但是不会被同步到其他节点上(即保证当前节点依然可用);
	3. 当网络稳定时，当前实例新的注册信息被同步到其他节点；

缓存行是处理器高速缓存中最小的存储单位，一般是64字节。内存中的连续64字节会被加载到一个缓存行。内存中的连续64字节会被加载到一个缓存行中。如果访问一个long数组，当数组中的一个值被加载到缓存中，它会额外加载另外7个；其实Java对象的相邻成员变量会加载到同一缓存行中。

伪共享：如果多个线程操作不同的成员变量，但是这些变量存储在同一个缓存行，如果有处理器更新了缓存行的数据并刷新到主存后根据缓存一致性原则，其他处理器将失效缓存行(I状态)导致缓存未命中，需要重新去内存中读取最新数据，这就是伪共享问题。特别是不同的线程操作同一个缓存行，需要发出RFO(Request for Owner)信号锁定缓存行，保证写操作的原子性，此时其他线程不能操作这个缓存行，这将对效率有极大的影响。

越靠近CPU的缓存越快也越小。所以L1缓存很小但很快，并且紧靠在使用它的CPU内核。L2大一些，也慢一些，并且仍然只能被一个单独的CPU核使用。L3在现代多核机器中更普遍，仍然更大、更慢，并且被单个插槽上的所有CPU核共享。最后是一块主存，由全部插槽上的所有CPU核共享。

JDK6解决伪共享：缓存行填充Padding无用的字段。
JDK7解决伪共享：缓存行填充Padding，在JDK7已经不适用了，因为JDK7会优化掉无用的字段。需要使用继承的办法来避免填充被优化掉。把Padding放在父类中，可以避免优化。
JDK8解决伪共享：被原生支持，添加@Contended注解。需要添加JVM参数：-XX:-RestrictContended

AKKA是Java虚拟机平台上构建高并发、分布式和容错应用的工具包和运行时。AKKA用Scala语言开发，同时提供了Scala和Java的开发接口。AKKA处理并发的方法基于Actor模型，Actor之间通信的唯一机制就是消息传递。
AKKA特点：
	1. 对并发模型进行了更高的抽象；
	2. 是异步、非阻塞、高性能的事件驱动编程模型；
	3. 是轻量级事件处理(1GB内存可容纳百万级别个Actor)；
	4. 提供了一种称为Actor的并发模型，其粒度比线程更小，可以在系统中启用大量的Actor；
	5. 它提供了一套容错机制，允许在Actor出现异常时进行一些恢复或重置操作；
	6. AKKA既可以在单机上构建高并发程序，也可以在网络中构建分布式程序，并提供位置透明的Actor定位服务；
	
因此，企业IT所面临的首要挑战就是整合企业中大量竖桶型(silo-ed)的IT系统，支撑日益复杂的业务流程，进行高效的业务决策和支撑业务快速变化。
在这种背景下，IBM等公司提出了SOA(面向服务的架构)理念，将应用系统抽象成一个个粗粒度的服务，构建松耦合服务架构，可以通过业务流程对服务进行灵活组合，提升企业IT资产复用，提高了系统的适应性、灵活性和扩展性，解决"信息孤岛"问题。

微服务架构首先要面对分布式架构的内生复杂性。微服务框架需要能够解决服务通信和服务治理的复杂性，比如服务发现、熔断、限流、全链路追踪等挑战。

SOA采用中心化的服务总线架构，解耦了业务逻辑和服务治理逻辑；微服务架构回归了去中心化的点对点调用方式，在提升敏捷性和可伸缩性的同时，也牺牲了业务逻辑和服务治理逻辑解耦所带来的灵活性。
为了解决上述挑战，社区提出了ServiceMesh(服务网格)架构。它重新将服务治理能力下沉到基础设施，在服务的消费者和提供者两侧以独立进程的方式部署。
这样既达到了去中心化的目的，保障了系统的可伸缩性；也实现了服务治理和业务逻辑的解耦，二者可以独立演进不互相干扰，提升了整体架构演进的灵活性。同时服务网格架构减少了对业务逻辑的侵入，降低了多语言支持的复杂性。

Istio提供了一系列高阶的服务治理能力，比如：服务发现和负载均衡，渐进式交付(灰度发布)，混沌注入与分析，全链路追踪，零信任网络安全等，可以供上层业务系统将其编排到自己的IT架构和发布系统之中。
但Service Mesh不是银弹，其架构选择是通过增加部署复杂性(sidecar)和损失性能(增加两跳),来换取架构的灵活性和系统的可演化性。

以上就是传统架构和现代架构的一个简单比对，现在架构上整个消息的同步、存储和索引流程，并没有变复杂太多。现代架构的实现本质上是把传统架构内本地存储和索引都搬到云上，最大挑战是需要集中管理全量消息的存储和索引，带来的好处是实现多端同步、消息漫游以及在线检索。可以看到现代架构中最核心的就是两个消息库“消息同步库”和“消息存储库”，以及对“消息存储库”的"消息索引"的实现。

Survivor的存在意义就是减少被送到老年代的对象，进而减少MajorGC的发生。Survivor的预筛选保证，只有经历一定次数MinorGC还能在新生代中存活的对象，才会被送到老年代。

Future接口代表了一个异步任务的结果，提供了相应方法判断任务是否完成或者取消。RunnableFuture同时继承了Future和Runnable，是一个可运行、可知结果的任务，FutureTask是具体的实现类。

public class FutureTask<V> implements RunnableFuture<V> {
	private volatile int state;
	//The underlying callable; nulled out after runing
	private Callable<V> callable;
	//The result to return or exception to throw from get()
	private Object outcome;
	//The thread running the callable; CASed during run();
	private volatile Thread runner;
	//Treiber stack of waiting threads
	private volatile WaitNode waiters;
	
	...
}

Future模式之CompletableFuture

public class CompletableFuture<T> implements Future<T>, CompletionStage<T> {
	...
}

CompletableFuture是JDK8新增的API，该类实现Future和CompletionStage两个接口，提供了非常强大的Future的扩展功能，可以简化异步编程的复杂性，提供了函数式编程的能力，可以通过回调的方式处理计算结果，并且提供了转换和组合CompletableFuture的方法。

JWarmup的基本原理：根据前一次程序运行的情况，记录下热点方法、类编译顺序等信息，在应用下一次启动的时候积极加载相关的类，并积极编译相关的方法，进而应用启动后可以直接运行编译好的Java代码(C2编译)。
JWarmup典型的用法：
	1. 在Beta灰度环境，进行应用压测，记录下热点方法、类编译顺序等信息；
	2. 在Production环境，使用提前记录的profiling data提前编译热点方法；

-------------------------------------------------------------
什么是Gossip协议：
Gossip Protocol利用一种随机的方式将信息散播到整个网络中。正如Gossip本身的含义一样，Gossip协议的工作流程即类似于绯闻的传播，或者流行病的传播。具体而言Gossip Protocol可以分为Push-based和Pull-based两种。
Push-based Gossip Protocol的具体工作流程如下：
	1. 网络中的某个节点随机的选择其他b个节点作为传输对象。
	2. 该节点向其选中的b个节点传输相应的信息
	3. 接收到信息的节点重复完成相同的工作

Pull-based Gossip Protol的协议过程刚好相反：
	1. 某个节点v随机的选择b个节点询问有没有最新的信息
	2. 收到请求的节点回复节点v其最近未收到的信息
当然，为了提高Gossip协议的性能，还有基于Push-Pull的混合协议。同时需要注意的是Gossip协议并不对网络的质量做出任何要求，也不需要loss-free的网络协议。Gossip协议一般基于UDP实现，其自身即在应用层保证了协议的robustness。

仅需要O(log(N))个回合，Gossip协议即可将信息传递到所有的节点。根据分析可得，Gossip协议具有以下的特点：
	- 低延迟；仅仅需要O(log(N))个回合的传递时间；
	- 非常可靠；仅有1/ncb - 2个节点不会收到信息；
	- 轻量级；每个节点传送了cblog(N)次信息；

memberlist是HashiCorp公司开源的Gossip库，这个库被Consul(也是HashiCorp公司开源)所引用。
-------------------------------------------------------------
InnoDB为了让表锁和行锁共存而使用了意向锁。
如果没有意向锁，事务B为了获取表级锁，需要进行下列步骤：
	step1：判断表是否已被其他事务用表锁锁表
	step2：判断表中的每一行是否已被行锁锁住。

注意step2中通过遍历查询，这样的判断方法效率实在不高，因为需要遍历整个表。

于是就有了意向锁。在意向锁存在的情况下，事务A必须先申请表的意向共享锁，成功后再申请一行的行锁。

在意向锁存在的情况下，上面的判断可以改成
	step1：不变
	step2：发现表上有意向共享锁，说明表中有些行被共享行锁锁住了，因此，事务B申请表的写锁会被阻塞。
结论：
	1. 申请意向锁的动作是数据库完成的，就是说，事务A申请一行的行锁的时候，数据库会自动先申请表的意向锁，不需要显式申请；
	2. IX(意向排他锁)，IS(意向共享锁)是表级锁，不会和行级的X，S锁发生冲突。只会和表级的X,S发生冲突。
意向锁的存在是为了协调行锁和表锁的关系，支持多粒度(行锁和表锁)的锁并存。	
例子：事务A修改user表的记录r，会给记录r上一把行级的排他锁（X），同时会给user表上一把意向排他锁（IX），这时事务B要给user表上一个表级的排他锁就会被阻塞。意向锁通过这种方式实现了行锁和表锁共存且满足事务隔离性的要求。

注意：上了行级X锁后，行级X锁不会因为有别的事务上了IX而阻塞，MySQL允许多个行级X锁同时存在，只要不是同一行的锁就可以。

间隙锁可用于防止幻读，保证索引间不会被插入数据。

查看事务、锁的SQL:
select * from information_schema.innodb_locks;
select * from information_schema.innodb_lock_waits;
select * from information_schema.innodb_trx;	

public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer
	implements java.io.Serializable {
	...
	/* Condition implements for a AbstractQueuedSynchronizer serving as the basis of a Lock implementation.
	
	Method document for this class describes mechanics, not behavioral specifications from the point of view of Lock and Condition users. Exported versions of this class will in general need to be accompanied by documentation describing condition semantics that rely on those of the associated AbstractQueuedSynchronizer.
	This class is Serializable, but all fields are transient, so deserialized conditions have no waiters.
	*/
	public class ConditionObject implements Condition, java.io.Serializable {
		private static final long serialVersionUID = *L;
		private transient Node firstWaiter;
		private transient Node lastWaiter;
		
	}
	...
}

Resilience4J-Retry组件：
	maxAttempts: 默认值3，最大重试次数
	waitDuration: 默认值500ms, 固定重试间隔
	intervalFunction: 默认值numberOfAttempts->waitDuration，用来改变重试时间间隔，可以选择指数退避或者随机时间间隔
	retryOnResultPredicate: result->false, 自定义结果重试规则，需要重试的返回true
	retryOnExceptionPredicate: throwable -> true, 自定义异常重试规则，需要重试的返回true
	retryExceptions: empty，需要重试的异常列表
	ignoreExceptions: empty, 需要忽略的异常列表

如果Resilience4J的Retry, CircuitBreaker, BulkHead, RateLimiter同时注解在方法上 ，默认的顺序是Retry>CircuitBreaker>RateLimiter>Bulkhead，即先控制并发再限流然后熔断最后重试。

实现通道相关系统间联动：支付通道故障时，一方面通过消息组件通知到营销活动、退款等系统，协助进行活动下线、通道退款关闭等处理，减少通道故障对其他系统的影响；另一方面以接口方式通知业务方系统，协助业务方进行故障分析。

Unsafe是位于sun.misc包下的一个类，主要提供一些用于执行低级别、不安全操作的方法，如直接访问系统内存资源、自主管理内存资源等，这些方法在提升Java运行效率、增强Java语言底层资源操作能力方面起到了很大的作用。但由于Unsafe类使用Java语言拥有了类似C语言指针一样操作内存空间的能力，无疑增加了程序发生相关指针问题的风险。在程序中过度、不正确使用Unsafe类会使得程序出错的概率变大。
Unsafe提供的API可分为内存操作、CAS、Class相关、对象操作、线程调度、系统信息获取、内存屏障、数组操作等几类。

通常，我们在Java中创建的对象都处于堆内内存（heap）中，堆内内存是由JVM所管控的Java进程内存，并且它们遵循JVM的内存管理机制，JVM会采用垃圾回收机制统一管理堆内存。与之相对的是堆外内存，存在于JVM管控之外的内存区域，Java中对堆外内存的操作，依赖于Unsafe提供的操作堆外内存的native方法。

使用堆外内存的原因：
	1. 对垃圾回收停顿的改善。由于堆外内存是直接受操作系统管理而不是JVM，所以当使用堆外内存时，即可保持较小的堆内内存规模，从而在GC时减少回收停顿对于应用的影响；
	2. 提升程序IO操作的性能。在通常IO通信过程中，会存在堆内内存到堆外内存的数据拷贝操作，对于需要频繁进行内存空间数据拷贝且生命周期较短的暂存数据，都建议存储到堆外内存。

DirectByteBuffer是Java用于实现堆外内存的一个重要类，通常用在通信过程中做缓冲池，如在Netty、MINA等NIO框架中应用广泛。DirectByteBuffer对于堆外内存的创建、使用、销毁等逻辑均由Unsafe提供的堆外内存API来实现。

CAS是一条CPU的原子指令(cmpxchg指令)，不会造成数据不一致问题，Unsafe提供的CAS方法(compareAndSwap***)底层实现即为CPU指令cmpxchg。

在Lambda表达式实现上，通过invokedynamic指令调用引导方法生成调用点，在此过程中，会通过ASM动态生成字节码，而后利用Unsafe的defineAnonymousClass方法实现相应的函数式接口的匿名类，然后再实例化此匿名类，并返回此匿名类中函数式方法的方法句柄关联的调用点；而后可以通过此调用点实现相应Lambda表达式定义逻辑的功能。

Unsafe类的public native Object allocateInstance() throws InstantiationException;绕过构造方法、初始化代码来创建对象。

Unsafe中提供allocateInstance方法，仅通过Class对象就可以创建此类的实例对象，而且不需要调用其构造函数、初始化代码、JVM安全检查等。它抑制修饰符检测，也就是即使构造器是private修饰的也能通过此方法实例化，只需提供类对象即可创建相应的对象。由于这种特性，allocateInstane在java.lang.invoke, Objenesis(提供绕过构造器的对象生成方式), Gson(反序列化时用到)中都有相应的应用。

Unsafe类与数组相关的arrayBaseOffset与arrayIndexScale两个方法，两者配合起来使用，即可定位数组中每个元素在内存中的位置。这两个和数组操作相关的方法，在AtomicIntegerArray(可以实现对Integer数组中每个元素的原子性操作)中有典型的应用。通过Unsafe的arrayBaseOffset, arrayIndexScale分别获取数组首元素的偏移地址base及单个元素大小因子scale。后续相关原子性操作，均依赖于这两个值进行数组中元素的定位。如getAndAdd方法即通过checkedByteOffset方法获取某数组元素的偏移地址，而后通过CAS实现原子性操作。

在JDK8中Unsafe引入内存屏障，用于定义内存屏障(也称为内存栅栏，内存栅障，屏障指令等，是一类同步屏障指令，是CPU或者编译器在对内存随机访问的操作中的一个同步点，使得此点之前的所有读写操作都执行后才可以开始执行此点之后的操作)，避免代码重排序。

//内存屏障，禁止load操作重排序。屏障前的load操作不能被重排序到屏障后，屏障后的load操作不能重排序到屏障前
public native void loadFence();
//内存屏障，禁止store操作重排序。屏障前的store操作不能重排序到屏障后，屏障后的store操作不能重排序到屏障前
public native void storeFence();
//内存屏障，禁止load,store操作重排序
public native void fullFence();

在JDK8中引入了一种锁的新机制：StampedLock，可以看成是读写锁的一个改进版本。StampedLock提供了一种乐观读锁的实现，这种乐观读锁类似于无锁的操作，完全不会阻塞写线程获取写锁，从而缓解读多写少时写线程"饥饿"现象。由于StampedLock提供的乐观读锁不阻塞写线程获取读锁，当线程共享变量从主内存load到工作内存时，会存在数据不一致问题，所以当使用StampedLock的乐观锁时，需要遵从使用模式来确保数据的一致性。

JVM规范要求每一个字节码文件都要由十部分按照固定顺序组成，整体结构如下：
	1. 魔数: Magic
	2. 版本号: Version
	3. 常量池：constant_pool
	4. 访问标志：access_flag
	5. 当前类索引：this_class
	6. 父类索引：super_class
	7. 接口索引：interface
	8. 字段表：fields
	9. 方法表：methods
	10. 附加属性：attributes

紧跟着主版本号之后的常量池入口。常量池中存储两类常量：字面量与符号引用。字面量为代码中声明为final的常量值，符号引用如类和接口的全局限定名、字段的名称和描述符、方法的名称和描述符。常量池整体上分为两部分：常量池计数器以及常量池数据区。

操作数栈和字节码：
JVM的指令集是基于栈而不是寄存器，基于栈可以具备很好的跨平台性(因为寄存器指令集往往和硬件挂钩)，但是缺点在于，要完成同样的操作，基于栈的实现需要更多指令才能完成(因为栈只是一个LIFO结构，需要频繁压栈出栈)。另外，由于栈是在内存实现的，而寄存器是在CPU的高速缓存区，相比较而言，基于栈的速度要慢很多，这也是为了跨平台而做出的牺牲。

字节码增强技术：
	1. AOP
	2. ASM
	3. CGLIB
	4. AspectJ
	5. Java Proxy 
	6. javassist
	7. Instrumentation 

ASM是在指令层次上操作字节码，在指令层次上操作字节码的框架实现起来非常晦涩。另一个源代码层次操作字节码的框架：Javassist。

Instrument是JVM提供的一个可以修改已加载类的类库，专门为Java语言编写的插桩服务提供支持。它需要依赖JVMTI的Attach API机制实现。在JDK1.6之前，Instrument只能在JVM刚启动开始加载类时生效，而在JDK1.6之后，Instrument支持了在运行时对类定义的修改。要使用Instrument的类修改功能，需要实现它提供的ClassFileTransformer接口，定义一个类文件转换器。接口中的transform()方法会在类文件被加载时调用，而在transform方法里利用ASM或Javassist对传入的字节码进行改写或替换，生成新的字节码数组后返回。

使用Java层面的工具定位内存区域(堆内内存，Code区域或者使用unsafe.allocateMemory和DirectByteBuffer申请的堆外内存)
在项目中添加-XX:NativeMemoryTracking=detail JVM参数重启JVM，使用命令jcmd <pid> VM.native_memory_detail查看内存分布。

pmap查看内存分布 

降低软件复杂性的一般原则和方法 

HashMap线程不安全的场景：
	1. 多线程put操作后，get操作导致死循环(JDK7中)；
	2. 多线程put非空元素后，get操作得到NULL值；
	3. 多线程put操作，导致元素丢失。

临键锁：Next-Key Lock

InnoDB下行锁可细分为：记录锁Record Lock, 间隙锁Gap Lock, 临键锁Next-Key Lock。是基于索引实现的。
临键锁：记录锁与间隙锁组合起来用就叫做Next-Key Lock，就是将键及其两边的间隙加锁(向左扫描到第一个比给定参数小的值，向右扫描到第一个比给定参数大的值，然后以此为界，构建一个区间)。

利用Next-Key Lock可以阻止其他事务在锁定区间内插入数据，因此在一定程度上解决了幻读问题。

InnoDB通过MVCC实现了在可重复读RR事务隔离级别下不加锁实现快照读的机制，所以所有的行级锁，都不会影响到其他事务中的快照读。

间隙锁存在的目的是为了防止事务执行过程中，另外一个事务对间隙的插入，能够有效避免幻读的发生。
正是因为间隙锁的存在目的，所以多个事务可以同时对同一个间隙加锁，即使它们加的都是排它锁。(事实上，考虑另一种常见情况，事务 1 持有间隙锁 (1， 3]，事务 2 持有间隙锁 (3, 5)，此时将记录 3 删除，那么事务 1 与事务 2 持有的间隙锁都将变成 (1, 5)，如果强制间隙锁的互斥，那么这种情况下就会产生错误)

在读已提交RC与读未提交RU事务隔离级别下，InnoDB会自动禁用间隙锁。

临键锁的加锁场景：
	1. 通过主键或唯一键进行范围查询，会加大于查询范围前开后闭最小范围的临键锁；
	2. 通过非主键或唯一键查询，会锁定对应索引记录及其之前的间隙；
	3. 如果没有建立索引，那么在查询过程中实际上扫描的是全表，所以会锁全表。不过对于select * from tb where *** limit 1这样的语句来说，实际扫描在首次遇到匹配行即结束，所以会锁此行前所有间隙。

MySQL如何避免死锁：
	1. 设置超时。innodb_lock_wait_timeout
	2. 主动死锁检测；通过innodb_deadlock_detect设置为on或off来开启或关闭主动死锁检测机制。
	3. 拆分字段实现单条记录并发度的下降。
	
InnoDB的每个表都会有聚集索引：
	1. 如果定义了主键，主键就是聚集索引；
	2. 如果没有定义主键，则第一个非空unique列是聚集索引；
	3. 否则,InnoDB会创建一个隐藏的row-id作为聚集索引；

分代回收是基于一个事实：对象的生命周期不同，所以针对不同生命周期的对象可以采取不同的回收方式，以便提高回收效率。

GC优化一般步骤可以为：确定目标、优化参数、验收结果。

JVM动态年龄计算：Hotspot遍历所有对象时，按照年龄从小到大对其所占用的大小进行累积，当累积的某个年龄大小超过了survivor区的一半时，取这个年龄和MaxTenuringThreshold中更小的一个值，作为新的晋升年龄阈值。本案例中，调优前：Survivor区=64M, desired survivor=32M，此时Survivor区中age<=2的对象累计大小为41M，42M大于32M，所以晋升年龄阈值被设置为2，下次Minor GC时将年龄超过2的对象被晋升到老年代。

JVM引入动态年龄计算，主要基于如下两点考虑：
	1. 如果固定按照MaxTenuringThreshold设定的阈值作为晋升条件：
		a):MaxTenuringThreshold设置的过大，原本应该晋升的对象一直停留在Survivor区，直到Survivor区溢出，一旦溢出发生，Eden+Survivor中对象将不再依据年龄全部晋升到老年代，这样对象老化的机制就失效了；
		b):MaxTenuringThreshold设置的过小，"过早晋升"即对象不能在新生代充分被回收，大量短期对象被晋升到老年代，老年代空间迅速增长，引起频繁的Major GC。分代回收失去了意义，严重影响GC性能。
	2. 相同应用在不同时间的表现不同：特殊任务的执行或者流量成分的变化，都会导致对象的生命周期分布发生波动，那么固定的阈值设定，因为无法动态适应变化，会造成和上面相同的问题。
总结来看，为了更好的适应不同程序的内存情况，虚拟机并不总是要求对象年龄必须达到MaxTenuringTHreshold再晋升到老年代。

CMS:如果仅扫描老年代中对象，即以老年代中对象为根，判断对象是否存在引用，上图中，对象A因为引用存在新生代中，它在Remark阶段就不会被修正标记为可达，GC时就会被错误回收。
新生代对象持有老年代中对象的引用，这种情况称为"跨代引用"。因为它的存在，Remark阶段必须扫描整个堆来判断对象是否存活。包括图中灰色的不可达对象。
灰色对象已经不可达，但仍然需要扫描的原因：新生代GC和老年代的GC是各自分开独立进行的，只有MinorGC时才会使用根搜索算法，标记新生代对象是否可达，也就是说虽然一些对象已经不可达，但在MinorGC发生前不会被标记为不可达，CMS也无法辨认哪些对象存活，只能全堆扫描(新生代+老年代)。由此可见，堆中对象的数目影响了Remark阶段耗时。

分析GC日志可以得到同样的规律，Remark耗时>500ms时，新生代使用率都在75%以上。这样降低Remark阶段耗时问题转换成如何减少新生代对象数量。

新生代中对象的特点是朝生夕灭，这样如果Remark前执行一次Minor GC，大部分对象就会被回收。CMS就采用了这样的方式，在Remark前增加一个可中断的并发预清理(CMS-concurrent-abortable-preclean)，该阶段主要工作仍然是并发标记对象是否存活，只是这个过程可被中断。此阶段在Eden区使用超过2M时启动，直到Eden区空间使用率达到50%时中断。当然2M和50%都是默认的阈值，可以通过参数修改。如果此阶段执行时等到了Minor GC，那么灰色对象被回收，Remark阶段需要扫描的对象就少了。

除此之外，CMS为了避免这个阶段没有等到Minor GC而陷入无限等待，提供了参数CMSMaxAbortablePrecleanTime，默认为5S，含义是如果可中断的预清理执行超过5S，不管有没有发生Minor GC，都会中止此阶段，进入Remark。

根据GC日志红色标记显式，可中断的并发预清理执行了5.35S,超过了设置的5S被中断，期间没有等到Minor GC，所以Remark时新生代仍然有很多对象。
对于这种情况，CMS提供了CMSScavengeBeforeRemark参数，用来保证Remark前强制进行一次MinorGC。

总结：由于跨代引用的存在，CMS在Remark阶段必须扫描整个堆，同时为了避免扫描时新生代有很多对象，增加了可中断的预清理阶段用来等待Minor GC的发生。只是该阶段有时间限制，如果超时等不到Minor GC，Remark时新生代仍然有很多对象，我们的调优策略是：通过参数强制Remark前进行一次Minor GC，从而降低Remark阶段的时间。
--------------------------------
其实新生代GC同样存在类似的问题，即老年代可能持有新生代对象引用，所以Minor GC时也必须扫描老年代。
JVM是如何避免Minor GC时扫描全堆的?

经过统计信息显示，老年代持有新生代对象引用的情况不足1%，根据这一特性JVM引入了卡表(Card Table)来实现这一目的。

卡表的具体策略是将老年代的空间分成大小为512B的若干张卡(Card)。卡表本身是单字节数组，数组中的每个元素对应着一张卡，当发生老年代引用新生代时，虚拟机将该卡对应的卡表元素设置为适当的值。如图所示，卡表3被标记为脏(卡表还有另外的作用，标识并发标记阶段哪些块被修改过)，之后Minor GC时通过扫描卡表就可以很快识别哪些卡中存在老年代指向新生代的引用。这样JVM通过空间换时间的方式，避免了全堆扫描。
--------------------------------
总结来说，CMS的设计聚焦在获取最短的时延，为此不遗余力地做了很多工作，包括尽量让应用程序和GC线程并发、增加可中断的并发预清理阶段、引入卡表等，虽然这些操作牺牲了一定吞吐量但获得了更短的回收停顿时间。

什么时候可能会触发STW的Full GC?
	1. Perm空间不足；
	2. CMS GC时出现promotion failed和concurrent mode failure(concurrent mode failure发生的原因一般是CMS正在进行，但是由于老年代空间不足，需要尽快回收老年代里面的不再使用的对象，这时停止所有的线程，同时终止CMS，直接进行Serial Old GC)；
	3. 统计得到Young GC晋升到老年代的平均大小大于老年代的剩余空间；
	4. 主动触发Full GC(执行jmap -histo:live <pid>)来避免碎片问题。

对于Redis的底层结构：
	1. 在Cluster模式下，一个Redis实例对应一个RedisDB(db0);
	2. 一个RedisDB对应一个Dict;
	3. 一个Dict对应2个Dictht, 正常情况只用到ht[0];ht[1]在Rehash时使用。

我们知道当HashMap中由于Hash冲突（负载因子）超过某个阈值时，出于链表性能的考虑，会进行Resize的操作。Redis也一样[Redis中通过dictExpand()实现]。

为了高效地匹配出数据库中所有符合给定模式的Key, Redis提供了Scan命令。该命令在每次调用的时候，返回符合规则的部分Key以及一个游标值Cursor(初始值使用0)，使用每次返回Cursor不断迭代，直到Cursor的返回值为0代表遍历结束。


Redis官方定义Scan特点如下：
	1. 整个遍历从开始到结束期间，一直存在于Redis数据集内的且符合匹配模式的所有Key都会被返回；
	2. 如果发生了rehash,同一个元素可能会返回多次，遍历过程中新增或者删除的key可能会被返回，也可能不会。


传统的权限模型有ACL(Access Control List)访问控制列表，RBAC(Role-Based Access Control)基于角色的访问控制等。以上模型比较适用于应用类型产品的权限管控，而数据类型的产品堆信息安全的要求更高，而且各类资源间的关系也更复杂，使用传统的模型难以将内部关系进行清晰的表达，所以需要在RBAC权限模型的基础上，扩展设计新的权限模型。

---------------------------------
Nginx运行CPU亲和力：
worker_processes 4;
worker_cpu_affinity 0001 0010 0100 1000;

Nginx事件处理模型：
events {
	use epoll;
	worker_connections 65535;
	multi_accept on;
}

Nginx的缓存功能有：proxy_cache / fastcgi_cache;
	- proxy_cache的作用是缓存后端服务器的内容，包括静态和动态；
	- fastcgi_cache的作用是缓存fastcgi生成的内容，很多情况是php生成的动态内容。
---------------------------------
2015年反应式(Reactive Stream)规范诞生，定义了如下四个接口：
	1. Subscription接口定义了连接发布者和订阅者的方法
	2. Publisher<T>接口定义了发布者的方法
	3. Subscriber<T>接口定义了订阅者的方法
	4. Processor<T, R>接口定义了处理器

Reactive Stream规范诞生后，RxJava从RxJava2.0开始实现Reactive Stream规范。

Reactive Stream基于流进行处理可以更高效地使用内存，把业务逻辑从模板代码中抽离出来，把代码从并发、同步问题中解脱出来，同时提高了代码的可读性。
Reactive Stream在某些方面是迭代器和观察者模式的结合，同时存在数据的Pull和Push。

JDK9中的Flow类定义了反应式编程的API，实际上就是拷贝了Reactive Stream的四个接口定义，然后放在java.util.concurrent.Flow类中。JDK9提供了SubmissionPublisher和ConsumerSubscriber两个默认实现。

JDK8引入了Stream用于流的操作，JDK9引入的Flow也是数据流的操作。不同点是：Stream更侧重于流的过滤、映射、整合、收集；而Flow更侧重于流的生产和消费。

处理器Processor: Processor位于Publisher和Subscriber之间，用于做数据转换。可以有多个Processer同时使用，组成一个处理链，链中最后一个处理器的处理结果发送给Subscriber。JDK没有提供任何具体的处理器。处理器同时是订阅者和发布者，接口的定义也是继承两者，作为订阅者接收数据，然后进行处理，处理完后作为发送者，再发布出去。

背压back pressure: Subscriber向Publisher请求消息，并通过提供的回调方法被激活调用。如果Publisher的处理能力比Subscriber强得多，需要有一种机制使得Subscriber可以通知Publisher降低生产速度。Publisher实现这种功能的机制被称为背压。提供数据生产者和消费者的消息机制，协调它们之间的产销失衡的情况。JDK9中的Flow API没有提供任何API来发信号或处理背压，需要开发者自行处理。JDK官方建议参考RxJava的背压处理方式。

事件顺序：反应式流中的事件顺序：
	1. 创建发布者和订阅者，分别是Publisher和Subscriber的实例；
	2. 订阅者调用发布者的subscribe进行订阅；
	3. 发布者调用订阅者的onSubscribe传递订阅Subscribtion
	4. 订阅者调用Subscription的request方法请求数据；
	5. 发布者调用订阅者的onNext方法传递数据给订阅者；
	6. 数据传递完成后发布者调用订阅者的onComplete方法通知完成；

Spring Reactor或者Reactive Streams和JDK8 Stream的区别是什么:两者最大的差别是Reactive Streams/Spring Reactor是Push-based, 而JDK8 Stream是Pull-based.
换言之，代码形式并不是Pull与Push的本质。从更深的层面说，Pull模式对应的是同步的、命令式的程序，Push模式对应的是异步的、非阻塞的、反应式的程序。

因此，虽然从代码形式上说JDK8 Stream和Reactive Streams的代码有点像，但从本质上来说，同步、阻塞的JDK8 Stream与异步、非阻塞的Reactive Streams有着很大的差别。

因此Reactive Stream不仅在形式上，以接口定义的形式对反应式编程做出了规范，更在实际层面上定义了TCK，用来保证相关实现确实满足了异步、非阻塞的要求。

自旋锁和适应性自旋锁

无锁：不锁住资源，多个线程中只有一个能修改资源成功，其他线程会重试；
偏向锁：同一个线程执行同步资源时自动获取资源；
轻量级锁：多个线程竞争同步资源时，没有获取资源的线程自旋等待锁释放；
重量级锁：多个线程竞争同步资源时，没有获取资源的线程阻塞等待唤醒；

CAS虽然很高效，但是也存在三大问题：
	1. ABA问题。CAS需要在操作值的时候检查内存值是否发生变化，没有发生变化才会更新内存值。但是如果内存值原来是A，后来变成了B，然后又变成了A，那么CAS进行检查时会发现值没有发生变化，但是实际上是有变化的。ABA问题的解决思路就是在变量前面添加版本号，每次变量更新的时候都把版本号加一，这样变化过程就从“A－B－A”变成了“1A－2B－3A”。JDK从1.5开始提供了AtomicStampedReference类来解决ABA问题，具体操作封装在compareAndSet()中。compareAndSet()首先检查当前引用和当前标志与预期引用和预期标志是否相等，如果都相等，则以原子方式将引用值和标志的值设置为给定的更新值。
	2. 循环时间长开销大。CAS操作如果长时间不成功，会导致一直自旋，给CPU带来非常大的开销。
	3. 只能保证一个共享变量的原子操作。对一个共享变量执行操作时，CAS能够保证原子操作，但是对多个共享变量操作时，CAS是无法保证操作的原子性的。JDK从1.5开始提供AtomicReference类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行CAS操作。

自旋锁本身是有缺点的，它不能代替阻塞。自旋等待虽然避免了线程切换的开销，但它要占用处理器时间。如果锁被占用的时间很短，自旋等待的效果就会非常好。反之，如果锁被占用的时间很长，那么自旋的线程只会白浪费处理器资源。所以，自旋等待的时间必须要有一定的限度，如果自旋超过限定次数(默认是10次，可以使用-XX:PreBlockSpin来更改)没有成功获得锁，就应当挂起线程。

自旋锁在JDK1.4.2中引入，使用-XX:+UseSpinning来开启。JDK6变为默认开启，并且引入了自适应的自旋锁(适应性自旋锁)。
自适应意味着自旋的时间(次数)不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会任务这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。

在自旋锁中，还有三种常见的锁形式：TicketLock, CLHLock和MCSLock。

Hotspot的对象头主要包括两部分数据：Mark Work(标记字段)，Klass Pointer(类型指针)。
Mark Word：默认存储对象的HashCode，分代年龄和锁标志位信息。这些信息都是与对象自身定义无关的数据，所以Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据。它会根据对象的状态复用自己的存储空间，也就是说在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。

Klass Point：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。

synchronized通过Monitor来实现线程同步，Monitor是依赖于底层的操作系统的Mutex Lock(互斥锁)来实现的线程同步。

四种锁状态对应的Mark Work内容。
锁状态		存储内容											存储内容 
无锁		对象的hashCode,对象分代年龄，是否是偏向锁			01
偏向锁		偏向线程ID，偏向时间戳，对象分代年龄，是否偏向锁	01
轻量级锁 	指向栈中锁记录的指针								00
重量级锁 	指向互斥量(重量级锁)的指针 							10

当一个线程访问同步代码块并获取锁时，会在Mark Word里存储锁偏向的线程ID。在线程进入和退出同步块时不再通过CAS操作来加锁和解锁，而是检测Mark Word里是否存储着指向当前线程的偏向锁。引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径，因为轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令即可。

偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态。撤销偏向锁后恢复到无锁（标志位为“01”）或轻量级锁（标志位为“00”）的状态。

偏向锁在JDK6及之后的版本是默认启用的。可以通过-XX:UseBiasedLocking=false，关闭之后程序默认会进入轻量级锁状态。
-------------------------------------------
轻量级锁是指当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。
当代码进入同步块的时候，如果同步对象状态为无锁状态(锁标志位为：01状态，是否为偏向锁为：0)，虚拟机首先将在当前线程的栈帧中建立一个名为锁记录(Lock Record)的空间，用于存储锁对象目前的MarkWord的拷贝，然后拷贝对象头中的Mark Word复制到锁记录中。
拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock Record里的Owner指针指向对象的Mark Word。
如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为00，表示此对象处于轻量级锁定状态。
如果轻量级锁的更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明多个线程竞争锁。
若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁。
-------------------------------------------
综上，偏向锁通过对比Mark Word解决加锁问题，避免执行CAS操作。而轻量级锁是通过用CAS操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。重量级锁是将除了拥有锁的线程以外的线程都阻塞。

公平锁是指多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中的第一个线程才能获得锁。公平锁的优点是等待锁的线程不会饿死。缺点是整体吞吐效率相对非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。

非公平锁是多个线程加锁时直接尝试获取锁，获取不到才会到等待队列的队尾等待。但如果此时锁刚好可用，那么这个线程可以无需阻塞直接获取到锁，所以非公平锁有可能出现后申请锁的线程先获取锁的场景。非公平锁的优点是可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU不必唤醒所有线程。缺点是处于等待队列中的线程可能会饿死，或者等很久才会获得锁。

可重入锁又称递归锁，是指在同一个线程在外层方法获取锁的时候，再进入该线程会自动获取锁(前提锁对象是同一个对象或者class)，不会因为之前已经获取过还没释放而阻塞。Java中ReentrantLock和synchronized都是可重入锁，可重入锁的一个优点是可一定程度避免死锁。
------------------------------------
容器本质上是把系统中同一个业务目标服务的相关进程合成一组，放在一个叫做namespace的空间中，同一个namespace中的进程能够互相通信，同时看不到其他namespace中的进程。每个namespace可以拥有自己独立的主机名、进程ID系统、IPC、网络、文件系统、用户等等资源，在某种程度上，实现了一个简单的虚拟：让一个主机上可以同时运行多个互不感知的系统。
此外，为了限制namespace对物理资源的使用，对进程能使用的CPU、内存等资源需要做一定的限制，这就是Cgroup技术，Cgroup是Control group的简写。比如我们常说的4c4g的容器，实际上是限制这个容器namespace中所用的进程，最多能够使用4核的计算资源和4GB的内存。
简而言之，Linux内核提供namespace完成隔离，Cgroup完成资源限制。namespace+Cgroup构成了容器的底层技术(rootfs是容器文件系统层技术)。
------------------------------------
大家都知道，JVM GC（垃圾对象回收）对Java程序执行性能有一定的影响。默认的JVM使用公式“ParallelGCThreads = (ncpus <= 8) ? ncpus : 3 + ((ncpus * 5) / 8)” 来计算做并行GC的线程数，其中ncpus是JVM发现的系统CPU个数。一旦容器中JVM发现了宿主机的CPU个数（通常比容器实际CPU限制多很多），这就会导致JVM启动过多的GC线程，直接的结果就导致GC性能下降。Java服务的感受就是延时增加，TP监控曲线突刺增加，吞吐量下降。

Netty底层基于JDK的NIO，为什么不直接基于JDK的NIO或者其他NIO框架：
	1. 使用JDK自带的NIO需要了解太多概念，编程复杂；
	2. Netty底层IO模型随意切换，而这一切只需要做微小的改动；
	3. Netty自带的拆包解包、异常检测等机制可以从NIO的繁重细节中脱离出来，只需关注业务逻辑；
	4. Netty解决了JDK的很多包括空轮询在内的Bug;
	5. Netty底层对线程,Selector做了很多细小的优化，精心设计的Reactor线程做到非常高效的并发处理；
	6. 自带各自协议栈，通用协议栈可以不用再次开发；
	7. Netty社区活跃，可随时邮件列表或提issue;
	8. Netty已经被各大RPC框架(Dubbo)、消息中间件(RocketMQ)、大数据通信(Hadoop)框架广泛的线上验证，健壮性强大。

在开源社区中，满足CP的产品：etcd,Zookeeper,Consule等。

Etcd底层Key的存储为BTree结构，查找时间复杂度为O(logN)，百万级甚至千万级Key的查找耗时区别不大。

MySQL里经常说的WAL技术: Write-Ahead Logging，关键点是先写日志，再写磁盘。write pos是当前记录的位置，一边写一边后移，写到第3号文件末尾后回到0号文件开头。checkpoint是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。
有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe.

redo log是InnoDB引擎特有的日志，而Server层也有自己的日志，称为binlog(归档日志)。

为什么会有redo log和binlog两份日志：最开始MySQL并没有InnoDB引擎。MySQL自带的引擎是MyISM，但是MyISM没有crash-safe的能力，binlog日志只能用于归档。而InnoDB是另一个公司以插件形式引入MySQL的，既然只依靠binlog是没有crash-safe能力的，所以InnoDB使用另外一套日志系统: redolog来实现crash-safe能力。

redo log和binlog的三点区别：
	1. redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用；
	2. redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑；
	3. redo log是循环写的，空间固定会用完；binlog是可以追加写入的。追加写是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。
	
由于redo log和binlog是两个独立的逻辑，如果不用两阶段提交，要么就是先写完redo log再写binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。

仍然用前面的update语句来做例子。假设当前ID=2的行，字段c的值是0，再假设执行update语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了crash，会出现什么情况呢？

先写redo log后写binlog。假设在redo log写完，binlog还没有写完的时候，MySQL进程异常重启。由于我们前面说过的，redo log写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行c的值是1。
但是由于binlog没写完就crash了，这时候binlog里面就没有记录这个语句。因此，之后备份日志的时候，存起来的binlog里面就没有这条语句。
然后你会发现，如果需要用这个binlog来恢复临时库的话，由于这个语句的binlog丢失，这个临时库就会少了这一次更新，恢复出来的这一行c的值就是0，与原库的值不同。

先写binlog后写redo log。如果在binlog写完之后crash，由于redo log还没写，崩溃恢复以后这个事务无效，所以这一行c的值是0。但是binlog里面已经记录了“把c从0改成1”这个日志。所以，在之后用binlog来恢复的时候就多了一个事务出来，恢复出来的这一行c的值就是1，与原库的值不同。

可以看到，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。简单说，redo log和binlog都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。

MySQL里面最重要的两个日志：物理日志redo和逻辑日志binlog。
redo log用于保证crash-safe能力。innodb_flush_log_at_trx_commit这个参数设置成1的时候，表示每次事务的redo log都直接持久化到磁盘。这个参数我建议你设置成1，这样可以保证MySQL异常重启之后数据不丢失。

sync_binlog这个参数设置成1的时候，表示每次事务的binlog都持久化到磁盘。这个参数我也建议你设置成1，这样可以保证MySQL异常重启之后binlog不丢失。

消除依赖、弱化依赖、控制依赖
事务中不包含外部调用

接收数据包的大致需要以下几个步骤：
	1. 网卡收到数据包；
	2. 将数据包从网卡硬件缓存转移到服务器内存中；
	3. 通知内核处理；
	4. 经过TPC/IP协议逐层处理；
	5. 应用程序通过read()从socket buffer读取数据。

火焰图是根据调用栈的样本集生产的可视化性能分析图。需要重点关注平顶，那里就是程序的CPU热点。调用树是另一种可视化分析的手段，与火焰图一样，也是根据同一份样本集而生成，按需选择即可。

JVMI(JVM Tool Interface)是JVM提供的一套标准的C/C++编程接口，是实现Debugger, Profiler, Monitor, Thread Analyser等工具的统一基础，在主流JVM中都有实现。
JNIEXPORT jint JNICALL Agent_OnLoad(JavaVM *vm, char *options, void *reserved);
使用C/C++实现该函数，并将代码编译为动态链接库(Linux为.so)，通过-agentpath参数将库的完整路径传递给Java进程，JVM就会在启动阶段的合适时机执行该函数。在函数内部，可以通过JavaVM指针参数拿到JNI和JVMTI的函数指针表，就拥有了与JVM进行各种复杂交互的能力。

在很多场景下，我们没有必要必须使用C/C++来开发JVMTI Agent，因为成本高且不易维护。JVM自身基于JVMTI封装了一套Java的Instrument API接口，允许使用Java语言开发Java Agent（只是一个jar包），大大降低了Agent的开发成本。社区开源的产品如Greys, Arthas, JVM-Sandbox, JVM-Profiler等都是纯Java编写的，也是以Java Agent形式来运行。
在Java Agent中，需要在jar包的MANIFEST.MF中的Premain-Class指定为一个入口类。
public static void premain(String[] args, Instrumentation ins) {
	//implement
}
在该方法内部，参数Instrumentation接口提供了Retransform Classes的能力，利用该接口就可以对宿主进程的Class进行修改，实现方法耗时统计、故障注入、Trace等功能。Instrumentation接口提供的能力较为单一，仅与Class字节码操作相关，但已经处于宿主进程环境内，就可以利用JMX直接获取宿主进程的内存、线程、锁等信息。无论是Instrument API还是JMX，它们内部仍是统一基于JVMTI来实现的。

只有在分场景讨论下才有意义。Sampling由于低开销的特性，更适合用在CPU密集型的应用中，以及不可接受大量性能开销的线上服务中。而Instrumentation则更适合用在IO密集型的应用中、对性能开销不敏感以及确实需要精确统计的场景中。社区中的Profiler更多的是基于Sampling来实现。

都是替换已经存在的class文件，redefineClasses是自己提供字节码文件替换掉已存在的class文件，retransformClasses是在已存在的字节码文件上修改后再替换之。

BTrace是基于Java语言的一个安全的、可提供动态追踪服务的工具。BTrace基于ASM、Java Attach API、Instrument开发，为用户提供了很多注解。依靠这些注解，我们可以编写BTrace脚本（简单的Java代码）达到我们想要的效果，而不必深陷于ASM对字节码的操作中不可自拔。



基于Instrument和Attach API前辈们创造出了诸如JProfiler、Jvisualvm、BTrace这样的工具。以ASM为基础发展出了cglib、动态代理，继而是应用广泛的Spring AOP。

Java是静态语言，运行时不允许改变数据结构。然而，Java 5引入Instrument，Java 6引入Attach API之后，事情开始变得不一样了。

------------------------------------------------------
			ReentrantLock					synchronized 
灵活性 		支持响应中断、超时、尝试取锁	不灵活
锁类型 		公平锁&非公平锁					非公平锁
条件队列	可关联多个条件队列				关联一个条件队列
锁实现机制	依赖AQS							监视器模式
可重入性 	可重入 							可重入
释放形式	必须显式unlock()				自动释放监视器 
------------------------------------------------------
AQS核心思想是，如果被请求的共享资源空闲，那么就将当前请求资源的线程设置为有效的工作线程，将共享资源设置为锁定状态；如果共享资源被占用，就需要一定的阻塞等待唤醒机制来保证锁分配。这个机制主要用的是CLH队列的变体实现的，将暂时获取不到锁的线程加入到队列中。
CLH：Craig、Landin and Hagersten队列，是单向链表，AQS中的队列是CLH变体的虚拟双向队列（FIFO），AQS是通过将每条请求共享资源的线程封装成一个节点来实现锁的分配。
AQS使用一个volatile的int类型的成员变量来表示同步状态，通过内置的FIFO队列来完成资源获取的排队工作，通过CAS完成对state值的修改。
AQS中的Node的waitStatus的几个枚举值：
	CANCELLED:为1，表示线程获取锁的请求已经取消了
	SIGNAL：为-1，表示线程已经准备好了，就等资源释放了
	CONDITION: 为-2，表示节点在等待队列中，节点线程等待唤醒
	PROPAGATE: 为-3，当前线程处于SHARED情况下，该字段才会使用
	0: 当一个Node被初始化的时候的默认值。

对cancelled节点状态的产生和变化有了了解，但是为什么所有的变化都是对Next指针进行操作，而没有对prev指针进行操作呢？什么情况下会会prev指针进行操作？
	1. 执行cancelAcquire的时候，当前节点的前置节点可能已经从队列中出去了(已经执行了try代码块中的shouldParkAfterFailedAcquire方法了)，如果此时修改prev指针，有可能会导致prev指向另一个移出队列的Node，因此这时变化prev指针不安全；
	2. shouldParkAfterFailedAcquire方法中，会执行下面的代码，其实就是在处理prev指针。shouldParkAfterFailedAcquire是获取锁失败的情况下才会执行，进入该方法后，说明共享资源已被获取，当前节点之前的节点都不会发生变化。因此这个时候变更prev指针比较安全。
	do {
		node.prev = pred = pred.prev;
	} while (pred.waitStatus > 0);


用DDD可以很好地解决领域模型到设计模型的同步、演化，最后再将反映了领域的设计模型转为实际的代码。
模型是我们解决实际问题所抽象出来的概念模型，领域模型则表达与业务相关的室是；设计模型则描述了所要构建的系统。

简单的业务系统采用贫血模型和过程化设计是没有问题的，但在业务逻辑复杂，业务逻辑、状态散落到大量方法中，原本的代码意图会渐渐不明确，我们将这种情况称为由贫血症引起的失忆症。
更好的是采用领域模型的开发方式，将数据和行为封装在一起，并与现实世界中的业务对象相映射。各类具备明确的职责划分，将领域逻辑分散到领域对象中。

解决复杂和大规模软件的武器可以被粗略地归为三类：抽象、分治和知识。

DDD的核心诉求是将业务架构映射到系统架构上，在响应业务变化调整业务架构时，也随之变化系统架构。而微服务追求业务层面的复用，设计出来的系统架构和业务一致；在技术架构上则系统模块之间充分解耦，可以自由地选择合适的技术架构，去中心化地治理技术和数据。

JVMTI是一套Native接口，在Java SE5之前，要实现一个Agent只能通过编写Native代码来实现。从Java SE5开始，可以使用Java的Instrumentation接口(java.lang.instrument)来编写Agent。无论是通过Native的方式还是通过Java Instrumentation接口的方式来编写Agent，它们的工作都是借助JVMTI来完成。

首先通过指定的进程ID找到目标JVM，然后通过Attach挂载到目标JVM上，执行加载Agent操作。VirtualMachine的Attach方法就是用来将Agent挂载到目标JVM上去的，而Detach则是将Agent从目标JVM卸载。

static AttachOperationFunctionInfo funcs[] = {
	{"agentProperties", get_agent_properties},
	{"datadump", data_dump},
	{"dumpheap", dump_heap},
	{"load", load_agent},
	{"properties", get_system_properties},
	{"threaddump", thread_dump},
	{"inspectheap", heap_inspection},
	{"setflag", set_flag},
	{"printflag", print_flag},
	{"jcmd", jcmd},
	{NULL, NULL}
};

findSocketFile方法用来查询目标JVM上是否已经启动了Attach Listener，它通过检查"tmp/"目录下是否在java_pid{pid}来进行实现。如果已经存在了，则说明Attach机制已经准备就绪，可以接受客户端的命令了，这个时候客户端就可以通过connect连接到目标JVM进行命令的发送，比如可以发送"load"命令来加载Agent。如果java_pid{pid}文件还不存在，则需要通过sendQuitTo方法向目标JVM发送一个"SIGBREAK"信号，让它初始化Attach Listener线程并准备接受客户端连接。可以看出，发送了信号之后客户端会循环等待java_pid{pid}这个文件，之后再通过connect连接到目标JVM上。

LruCache在美团DSP系统的应用场景
在美团DSP系统中广泛应用键值存储数据库，例如使用Redis存储广告信息，服务可以通过广告ID获取广告信息。每次请求都从远端的键值存储数据库中获取广告信息，请求耗时非常长。随着业务发展，QPS呈现巨大的增长趋势，在这种高并发的应用场景下，将广告信息从远端键值存储数据库中迁移到本地以减少查询耗时是常见解决方案。另外服务本身的内存占用要稳定在一个安全的区间内。面对持续增长的广告信息，引入LruCache + 键值存储数据库的机制来达到提高系统性能，维持内存占用安全、稳定的目标。

缓存命中率/缓存占用空间/缓存的逐出策略/缓存的过期策略

回滚日志不能一直保留，什么时候删除呢？答案是，在不需要的时候才删除。也就是说，系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志会被删除。
什么时候才不需要了呢？就是当系统里没有比这个回滚日志更早的read-view的时候。
基于上面的说明，不建议使用长事务，原因如下：
	1. 长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。
在MySQL5.5及以前的版本，回滚日志是跟数据字典一起放在ibdata文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。有些数据只有20G，而回滚段有200GB的库。最终只好为了清理回滚段，重建整个库。
	2. 除了回滚段，长事务还占用锁资源，也可能拖垮整个库。

可以在information_schema库的innodb_trx这个表中查询长事务，如下查询持续时间大于60秒的事务：
select * from information_schema.innodb_trx where time_to_sec(timediff(now(), trx_started)) > 60;
-------------------------------------------------------
电梯调度算法:
	1. 先来先服务算法: First Come First Service
	2. 最短寻找楼层时间优先:Shorted Seek Time First 
	3. 扫描算法: Scan
	4. Look算法：look算法是扫描算法的一种改进。对look算法而言，电梯同样在最底层和最顶层之间运行。但当look算法发现电梯所移动的方向上不再有请求时立即改变运行方向，而扫描算法则需要移动到最底层或者最顶层时才改变运行方向；
	5. SATF算法：最短访问时间优先
-------------------------------------------------------
B+树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数。

如何避免长事务对业务的影响：
	首先，从应用开发端来看：
		1. 确认是否使用了set autocommit=0。这个确认可以在测试环境开展，把MySQL的general_log开起来，通过general_log的日志来确认。一般框架设置了这个值，也就会提供参数来控制，目标就是改为1；
		2. 确认是否有不必要的只读事务。有些框架会习隔把任何语句都begin/commit框起来。某些业务不需要，比如多个select语句放在事务中。这种只读事务可以去掉。
		3. 业务连接数据库时候，根据业务评估，通过 set max_execution_time命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。
	其次，从数据库端来看：
		1. 监控information_schema.innodb_tr表，设置长事务阈值，超过就报警或者kill；
		2. percona的pt-kill工具；
		3. 在业务功能测试阶段输出所有的general_log，分析日志行为提前发现问题；
		4. 如果是MySQL5.6或者更新版本，把innodb_undo_tablespaces设置成2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。

在MySQL5.6引入的索引下推优化(index condition pushdown)，可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤到不满足条件的记录，减少回表次数。

为什么要重建索引：索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间。

MySQL里的锁：全局锁、表锁和行锁。

全局锁：就是对整个数据库实例加锁。MySQL提供了一个加全局锁的方法:flush tables with read lock(FTWRL);当需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的语句会被阻塞：数据的更新语句(数据的增删改)、数据定义语句(DML)和更新类事务的提交语句。
全局锁的典型使用场景是，做全局逻辑备份。

MySQL官方自带的逻辑备份工具是mysqldump。当mysqldump使用参数--single-transaction的时候，导数据之前会启动一个事务，来确保拿到一致性事务。而由于MVCC的支持，这个过程中数据可以正常更新。
你一定在疑惑，有了这个功能，为什么还需要FTWRL呢？一致性读是好，但前提是引擎要支持这个隔离级别。比如，对于MyISAM这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用FTWRL命令了。

MySQL表级别的锁有两种：表锁和元数据锁(meta data lock, MDL)

因此，在MySQL 5.5版本中引入了MDL，当对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。

在InnoDB事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。

当出现死锁以后，有两种策略：

一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数innodb_lock_wait_timeout来设置。
另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑。
在InnoDB中，innodb_lock_wait_timeout的默认值是50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过50s才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的。

但是，我们又不可能直接把这个时间设置成一个很小的值，比如1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。

所以，正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且innodb_deadlock_detect的默认值本身就是on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。
-----------------------------
InnoDB里面每个事务有一个唯一的事务ID，叫做transaction id。它是在事务开始的时候向InnoDB的事务系统申请的，是按照申请顺序严格递增的。
而每行数据也都有多个版本。每次事务更新数据的时候，都会生成一个新的数据版本，并且把transaction id赋值给这个数据版本的事务ID，记为row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息直接拿到它。
也就是说，数据表中的一行记录，其实可能有多个版本(row)，每个版本有自己的row trx_id。

在实现上，InnoDB为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在"活跃"的所有事务ID。活跃指的是，启动了但还没提交。
数组里面事务ID的最小值为低水位，当前系统里面已经创建过的事务ID的最大值加1记为高水位。
这个视图数组和高水位，就组成了当前事务的一致性视图(consistent read-view)。
而数据版本的可见性规则，就是基于数据的row trx_id和这个一致性视图的对比结果得到的。

用到一条规则：更新数据都是先读后写的，而这个读，只能读当前的值，称为"当前读"(current read)。
提到一个概念，叫做当前读。其实，除了update语句外，select语句如果加锁，也是当前读。
所以，如果把事务A的查询语句select * from t where id=1修改一下，加上lock in share mode或for update，也都能读到最新的数据。

事务的可重复读的能力是怎么实现的？
	可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。

而读提交和逻辑和可重复读的逻辑类似，它们最主要的区别是：
	1. 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；
	2. 在读已提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。

-----------------------------