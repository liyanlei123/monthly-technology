满二叉树第i层有2的(i-1)次幂个节点，n层的满二叉树共有2的n次幂-1个节点
------------------------------------------------
两个文件，每个文件中都有若干个url，找出两个文件中相同的url:
方案一：如果两个文件都很小，直接加载到内存，进行内部排序后，进行比较即可。
		如果文件很大，按照哈希，分别将两个文件拆分到可以内部排序的程度，然后分别两两比对即可；
方案二：如果预先知道相同的URL比较少，可以使用布隆过滤器。
------------------------------------------------
随机数a来生成随机数b(a != b)
// 由RandomA来生成RandomB
    // 前提条件a, b都大于1
    public static int random2Random(int a, int b) {
        if (a == b) {
            return getRandom(a);
        }

        if (a > b) { // a = 17, b = 5
            while (true) {
                int tmp = getRandom(a);
                if (tmp <= b * (a / b)) {
                    return tmp / (a / b);
                }
            }
        } else { // a < b
            // X = a * getRandom(a) + getRandom(a) 可等概率生成：0到(a^2 - 1)之间的数
            // 继续直到X >= b
            int nextA = a * a, num = 2;
            while (nextA < b) {
                nextA *= a;
                num++;
            }

            return getRandomNums(a, num);
        }
    }

    private static int getRandomNums(int x, int num) {
        int tmp = x * getRandom(x) + getRandom(x);

        while (num > 2) {
            tmp = x * tmp + getRandom(x);
            num--;
        }
        return tmp;
    }

    private static int getRandom(int x) {
        return ThreadLocalRandom.current().nextInt(x);
    }
------------------------------------------------
DDD方法论在系统建模过程中，可以为团队中的各个角色提供一套"统一语言"，避免组件划分过程中的边界错位，完成领域图预演、需求分析、架构模型、代码模型、测试等工作。
DDD的核心组件：
	1. 界限上下文；
	2. 实体；
	3. 值对象；
	4. 服务；
	5. 聚合；
	6. 聚合根；
	7. 仓储；
	8. 工厂；
------------------------------------------------
Eureka服务剔除的不是90秒没心跳的实例，剔除的是180秒没心跳的实例(Eureka的BUG导致)，如下：
加了两次duration值，com.netflix.eureka.lease.Lease#isExpired(long)

/* Renew the lease, use renewal duration if it was specified by the associated T during 
   registration, otherwise default duration is 90 seconds.
*/
public void renew() {
	lastUpdateTimestamp = System.currentTimeMillis() + duration;
}

/* Checks if the lease of a given com.netflix.appinfo.InstanceInfo has expired or not.
Note that due to renew() doing the "wrong" thing and setting lastUpdateTimestamp to +duration more than 
what it should be, the expiry will actually be 2 * duration. This is a minor bug and should only affect
 instance that ungracefully shutdown. Due to possible wide ranging impact to existing usage, this will
 not be fixed.
*/
public boolean isExired(long additionalLeaseMs) {
	return (evictionTimestamp > 0 || System.currentTimeMillis() > lastUpdateTimestamp + duration + additionalLeaseMs));
}
------------------------------------------------
选择排序：简单选择排序->树形选择排序(锦标赛排序)->堆排序 

TCP如何保证可靠传输：校验和、序列号、确认应答、超时重传、连接管理、流量控制、拥塞控制。
	1. 校验和；
	2. 确认应答和序列号；
	3. 超时重传；
	4. 连接管理：三次握手、四次挥手；
	5. 滑动窗口：流量控制和拥塞控制都是使用了滑动窗口来实现；
	6. 流量控制；
	7. 拥塞控制；

-XX:G1HeapRegionSize=xxx：使用G1时Java堆被分为大小统一的区Region。此参数可以指定每个heap区的大小。默认值将更加heap size算出最优解。最小值1M,最大值32M。
------------------------------------
所有的内部排序算法:
	1. 插入排序
		1.1 直接插入排序 
		1.2 其他插入排序: 折半插入排序，2-路插入排序，表插入排序
		1.3 希尔排序 
	2. 快速排序
	3. 选择排序 
		3.1 简单选择排序 
		3.2 树形选择排序 
		3.3 堆排序 
	4. 归并排序 
	5. 基数排序 
		5.1 多关键字的排序 
		5.2 链式基数排序
------------------------------------
-XX:+PrintGCApplicationStoppedTime:打印程序暂停时间
-XX:+PrintReferenceGC:GC清理了多少引用类型，查看各种引用对GC的影响。

GCViewer is a little tool that visualizes verbose GC output generated by Sun / Oracle, IBM, HP and BEA Java Virtual Machines. It is free software released under GNU LGPL.
You can start GCViewer (gui) by simply double-clicking on gcviewer-1.3x.jar or running java -jar gcviewer-1.3x.jar (it needs a java 1.8 vm to run).

分配速率的变化，会增加或降低GC暂停的频率，从而影响吞吐量。但只有年轻代的MinorGC受分配速率的影响，老年代GC的频率和持续时间不受分配速率(Allocation rate)的直接影响，而是受到提升速率(Promotion Rate)的影响。
有时候JVM很智能，会使用逃逸分析技术(escape analysis technique)来避免过度分配。简单来说，JIT编译器可以通过分析得知，方法创建的某些对象永远都不会"逃出"此方法的作用域。这时候就不需要在堆上分配这些对象，也就不会产生垃圾，所以JIT编译器的一种优化手段就是：消除内存分配。

过早提升: Premature Promotion 
提升速率(promotion rate), 用于衡量单位时间内从年轻代提升到老年代的数据量。一般使用 MB/sec 作为单位, 和分配速率类似。
JVM会将长时间存活的对象从年轻代提升到老年代。根据分代假设, 可能存在一种情况, 老年代中不仅有存活时间长的对象,也可能有存活时间短的对象。这就是过早提升：对象存活时间还不够长的时候就被提升到了老年代。
major GC 不是为频繁回收而设计的, 但 major GC 现在也要清理这些生命短暂的对象, 就会导致GC暂停时间过长。这会严重影响系统的吞吐量。
只能根据Minor GC计算提升速率。FGC的日志不能用于计算提升速率，因为Major GC会清理老年代中的一部分对象。
-------------------------------------------------------
让一个线程阻塞的方法: 
	1. LockSupport#park 
	2. Object#wait 
	3. Condition#await 
	4. Thread#join 
	5. Thread#sleep
	6. ExecutorService#invokeAll
	7. Future#get 
	8. ExecutorService#awaitTermination
	9. CountDownLath#await
	10. CyclicBarrier#await 
-------------------------------------------------------
OSI的七层分层：
	1. 物理层: 建立、维护、断开物理连接（由底层网络定义协议）
	2. 数据链路层：建立逻辑连接、进行硬件地址寻址、差错校验等功能(由底层网络定义协议)。将比特组合成字节进而组合成帧，用MAC地址访问介质，错误发现但不能纠正。
	3. 网络层：进行逻辑地址寻址，实现不同网络之间的路径选择；协议有：ICMP, IGMP, IPv4, IPv6；
	4. 传输层：定义传输数据的协议端口号，以及流控和差错校验。协议有：TCP, UDP，数据包一旦离开网卡即进入网络传输层。
	5. 会话层：建立、管理、终止会话。(在五层模型里已经合并到了应用层)；对应主机进程，指本地主机与远程主机正在进行的会话。
	6. 表示层：数据的表示、安全、压缩。(在五层模型里已经合并到了应用层)；格式有：Jpeg, ascii, decoic,加密格式等；
	7. 应用层：网络服务与最终用户的一个接口；协议有：HTTP, FTP, TFTP, SMTP, SNMP, DNS, TELNET, HTTPS, POP3, DHCP；

从一张大表读取数据，如何解决性能问题：
	1. 优化SQL语句：合理分页、join、order by、group by等合理使用。
	2. 增加合适的索引和合理使用索引；
	3. 设计合理的表结构；
	4. 分区表；
	5. 数据库的读写分离；
	6. 增加硬件配置：服务器、网络、IO、硬盘等；
	7. 数据库分库分表；
	8. 数据的冷热分离；
	9. 汇总表；
	10. 接入Spark；
	11. 接入Hive；
	12. 缓存；
	13. 开启查询缓存；
-------------------------------------------------------------------------------
R树是一种多级平衡树，它是B树在多维空间上的扩展。在R树中存放的数据并不是原始数据，而是这些数据的最小边界矩阵(MBR)，空间对象的MBR被包含于R树的叶节点中。在R树空间索引中，设计一些虚拟的矩阵目标，将一些空间位置相近的目标，包含在这个矩形内，这些虚拟的矩形作为空间索引，它含有所包含的空间对象的指针。虚拟矩形还可以进一步细分，即可以再套虚拟矩形形成多级空间索引。
R+树：在R树的构造中，要求虚拟矩形一般尽可能少地重叠，并且一个空间对通常仅被一个虚拟矩形所包含。但空间对象千姿百态，它们的最小矩形范围经常重叠。R+改进树的空间索引，为了平衡，它允许虚拟矩形互相重叠，并允许一个空间目标被多个虚拟矩形所包含。	

如何判断点在多边形内部？可以通过射线法来判断点是否在多边形内部。从该点出发沿X轴画一条射线，依次判断该射线与每条边的交点，并统计交点个数，如果交点数位奇数，则在多边形内部。如果交点数是偶数，则在外部。射线法对凸和非凸多边形都适用，复杂度为O(N),其中N是边数。
一棵R树满足如下性质：
	1. 除非它是根节点，所有叶子节点包含有m到M个记录索引(条目)。作为根节点的叶子节点所具有的记录个数可以少于m。通常m=M/2；
	2. 对应所有在叶子中存储的记录(条目)，I是最小的可以在空间中完全覆盖这些记录所代表的点的矩形(注意:此处的"矩形"是可以扩展到高维空间的)；
	3. 每一个非叶子节点拥有m至M个孩子节点，除非它是根节点；
	4. 对于在非叶子节点上的每一个条目，I是最小的可以在空间上完全覆盖这些条目代表的矩形；
	5. 所有叶子节点都位于同一层，因此R树是平衡树。


在运用X锁和S锁对数据对象加锁时，还需要约定一些规则，例如何时申请X锁或S锁、持锁时间、何时释放等。称这些规则为封锁协议(Locking Protocol)。对封锁方式规定不同的规则，就形成了各种不同的封锁协议。


数据库的三级封锁协议:
	一级封锁协议(对应read uncommitted);
	二级封锁协议(对应read committed);
	三级封锁协议(对应reapeatable read);
	四级封锁协议(对应serialization);

在含有N个关键字的B树上进行查找时，从根节点到关键字所在节点的路径上涉及的节点数不超过log[m/2]((N+1)/2) + 1。
一棵含有N个关键字的m阶的B树的最大高度是多少：log(ceil(m/2)) ((N + 1) / 2) + 1

B+树是应文件系统所需而出的一种B树的变种树。一棵m阶的B+树和m阶的B树的差异在于：
	1. 有n棵子树的节点中含有n个关键字；
	2. 所有叶子节点中包含了全部关键字的信息，及指向含有这些关键字记录的指针，且叶子节点本身依关键字的大小自小到大顺序链接；
	3. 所有的非终端节点可以看成是索引部分，节点中仅含有其子树(根节点)中的最大/最小关键字。

B*树是B+树的变种树，在B+树的基础上(所有的叶子节点包含了全部关键字信息，及指向含有这些关键字记录的指针)，B*树中非根和非叶子节点再增加指向兄弟的指针；B*树定义了非叶子节点关键字个数至少为(2/3)*M，即块的最低使用率为2/3(代替B+树的1/2)。

B+树的分裂：当一个结点满时，分配一个新的结点，并将原结点中1/2的数据复制到新结点，最后在父结点中增加新结点的指针；B+树的分裂只影响原结点和父结点，而不会影响兄弟结点，所以它不需要指向兄弟的指针。
B*树的分裂：当一个结点满时，如果它的下一个兄弟结点未满，那么将一部分数据移到兄弟结点中，再在原结点插入关键字，最后修改父结点中兄弟结点的关键字（因为兄弟结点的关键字范围改变了）；如果兄弟也满了，则在原结点与兄弟结点之间增加新结点，并各复制1/3的数据到新结点，最后在父结点增加新结点的指针。
所以，B*树分配新节点的概率比B+树要低，空间使用率更高。

一棵R树满足如下的性质：
	1. 除非它是根结点之外，所有叶子结点包含有m至M个记录索引（条目）。作为根结点的叶子结点所具有的记录个数可以少于m。通常，m=M/2。
	2. 对于所有在叶子中存储的记录（条目），I是最小的可以在空间中完全覆盖这些记录所代表的点的矩形（注意：此处所说的“矩形”是可以扩展到高维空间的）。
	3. 每一个非叶子结点拥有m至M个孩子结点，除非它是根结点。
	4. 对于在非叶子结点上的每一个条目，i是最小的可以在空间上完全覆盖这些条目所代表的店的矩形（同性质2）。
	5. 所有叶子结点都位于同一层，因此R树为平衡树。

实现一个保证迭代顺序的HashMap: 参考LinkedHashMap的实现。

public class LinkedHashMap<K, V> extends HashMap<K, V> implements Map<K, V> {
	static class Entry<K, V> extends HashMap.Node<K, V> {
		Entry<K, V> before, after;
		Entry(int hash, K key, V value, Node<K, V> next) {
			super(hash, key, value, next);
		}
	}
	
	private static final long serialVersionUID = 3801124242820219131L;
	//The head(eldest) of the doubly linked list.
	transient LinkedHashMap.Entry<K, V> head;
	//The tail(youngest) of the doubly linked list.
	transient LinkedHashMap.Entry<K, V> tail;
	//The iteration ordering method for this linked hash map:
	//true for access-order, false for insertion-order;
	final boolean accessOrder;

}


三者的递归公式：
	0-1背包： ks(i, t) = max {ks(i-1, t - V[i] * k)}; (0<=k<=1 && V[i] <= t)
	完全背包：ks(i, t) = max {ks(i-1, t - V[i] * k) + P[i] * k}; (0 <= k*V[i] <= t)
	多重背包：ks(i, t) = max {ks(i-1, t - V[i] * k) + P[i] * k}; (0<=k<=M[i] && 0 <= k*V[i] <= t)

简单工厂：最简单，能满足大部分日常需求；缺点：太简单，无法满足开闭原则，对多个产品的扩展不利。
工厂方法：
抽象工厂：缺点：增加一个产品族的话，会改动抽象工厂角色，具体工厂角色。改动比较多。

有向图强连通分量：在有向图G中，如果两个顶点Vi,Vj间(Vi>Vj)有一条从Vi到Vj的有向路径，同时还有从Vj到Vi的有向路径，则称两个顶点强连通(strongly connected)。如果有向图G的每两个顶点都强连通，称G是一个强连通图。有向图的极大强连通子图，称为强连通分量(strongly connected components)。

最小生成树:构造最小生成树可以有多种算法。其中多数算法利用了最小生成树的下列一种简称为MST的性质：假设N = (V, {E})是一个连通网，U是顶点集V的一个非空子集。若(u, v)是一条最小权值(代价)的边，其中u属于U，v属于V-U，则比存在一棵包含边(u,v)的最小生成树。(可以用反证法证明)
普里姆Prim算法和克鲁斯卡尔Kruskal算法是两个利用MST性质构造最小生成树的算法。

装饰(Decorator)模式的定义：指在不改变现有对象结构的情况下，动态地给该对象增加一些职责(即增加其额外功能)的模式，它属于对象结构型模式。
装饰(Decorator)模式的主要优点有：
	- 采用装饰模式扩展对象的功能比采用继承更加灵活；
	- 可以设计出多个不同的具体装饰类，创造出多个不同行为的组合。
装饰(Decorator)模式的缺点：装饰模式增加了许多个子类，如果过度使用会使程序变得复杂。
装饰模式的结构与实现：通常情况下，扩展一个类的功能会使用继承方式来实现。但继承具有静态特征，耦合度高，并且随着扩展功能的增多，子类会很膨胀。如果使用组合关系来创建一个包装对象（即装饰对象）来包裹真实对象，并在保持真实对象的类结构不变的前提下，为其提供额外的功能，这就是装饰模式的目标。

装饰模式的主要角色如下：
	- 抽象构件(Component)角色：定义一个抽象接口以规范准备接收附加责任的对象。
	- 具体构件(ConcreteComponent)角色：实现抽象构件，通过装饰角色为其添加一些职责。
	- 抽象装饰(Decorator)角色：继承抽象构件，并包含具体构件的实例，可以通过其子类扩展具体构件的功能。
	- 具体装饰(ConcreteDecorator)角色：实现抽象装饰的相关方法，并给具体构件对象添加附加的责任。

/* A Red-Black tree based NavigableMap implementation. The map is sorted according to the Comparable natural ordering of its keys, or by a Comparator provided at map creation time, depending on which constructor is used.

This implementation provides guaranteed log(n) time cost for the #containsKey, #get and #remove operations.
*/
public class TreeMap<K, V> extends AbstractMap<K, V> 
					implements NavigableMap<K, V>, Cloneable, java.io.Serializable {
	private final Comparator<? super K> comparator;
	private transient Entry<K, V> root;
	private transient int size;
	private transient int modCount = 0;
	...
	// Views
	/* Fields initialized to contain an instance of the entry set view the first time this view is requested. 
	* Views are stateless, so there's no reason to create more than one.
	*/
	private transient EntrySet entrySet;
	private transient KeySet<K> navigableKeySet;
	private transient NavigableMap<K, V> descendingMap;
	...
	// Red-black mechanics
	private static final boolean RED = false;
	private static final boolean BLACK = true;
	...
}

TreeMap继承AbstractMap，实现NavigableMap、Cloneable、Serializable三个接口。其中AbstractMap表明TreeMap为一个Map即支持key-value的集合， NavigableMap（更多）则意味着它支持一系列的导航方法，具备针对给定搜索目标返回最接近匹配项的导航方法 。

红黑树的五点规则：
	1、每个节点都只能是红色或者黑色
	2、根节点是黑色
	3、每个叶节点（NIL节点，空节点）是黑色的。
	4、如果一个结点是红的，则它两个子节点都是黑的。也就是说在一条路径上不能出现相邻的两个红色结点。
	5、从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。

红黑树的5个约束规则强制了红黑树的关键性质：从根到叶子的最长的可能路径不多于最短的可能路径的两倍长。

对于新节点的插入有如下三个关键地方：
	1. 插入新节点总是红色节点；
	2. 如果插入节点的父节点是黑色，能维持性质；
	3. 如果插入节点的父节点是红色，破坏了性质。故插入算法就是通过重新着色或旋转，来维持性质；

七大设计原则：
	1. 开闭原则: Open Closed Principle, OCP
	2. 里氏替换原则：Liskov Subsitution, LSP
	3. 依赖倒置原则：Dependence Inversion Principle, DIP
	4. 单一职责原则：Single Responsibility Principle, SRP
	5. 接口隔离原则：Interface Segregation Principle, ISP
	6. 迪米特法则：Law of Demeter, LoD;又叫做最少知识原则: Least Knowledge Principle: LKP
	7. 合成复用原则：Composite Reuse Principle, CRP;又叫做组合/聚合复用原则: Composition/Aggregate Reuse Principle, CARP

接口隔离原则和单一职责都是为了提高类的内聚性、降低它们之间的耦合性，体现了封装的思想，但两者是不同的：
	- 单一职责原则注重的是职责，而接口隔离原则注重的是对接口依赖的隔离；
	- 单一职责原则主要是约束类，它针对的是程序中的实现和细节；接口隔离原则主要约束接口，主要针对抽象和程序整体框架的构建；

这7种设计原则是软件设计模式必须尽量遵循的原则，各种原则要求的侧重点不同。其中，开闭原则是总纲，告诉我们要对扩展开放，对修改关闭；里氏替换原则告诉我们不要破坏继承体系；依赖倒置原则告诉我们要面向接口编程；单一职责原则告诉我们要实现类的职责单一；接口隔离原则告诉我们设计接口的时候要精简单一；迪米特法则告诉我们要降低耦合度；合成复用原则告诉我们要优先使用组合或者聚合关系复用，少用继承关系复用。

创建型模式的主要关注点是“怎样创建对象？”，它的主要特点是“将对象的创建与使用分离”。这样可以降低系统的耦合度，使用者不需要关注对象的创建细节，对象的创建由相关的工厂来完成。

实际上，JDK8种的Lambda表达式在大多数虚拟机种采用invokeDynamic指令实现，相对于匿名内部类在效率上会更高一些。

为类指定final修饰符，可以让类不可以被继承；如果指定了一个类为final,则该类所有的方法都是final的，Java编译器会寻找机会内联所有的final方法。内联对于提升Java运行效率作用重大，具体可参加Java运行期优化，能够使性能平均提高50%。

所有的private方法会隐式地被指定final修饰符，所以无须再为其指定final修饰符。

if-else语句，每个if条件语句都要加装计算，直到if条件语句为true为止。switch语句进行了跳转优化，Java中采用tableswitch或lookupswitch指令实现，对于多常量选择分支处理效率更高。经过试验证明：在每个分支出现概率相同的情况下，低于5个分支时if-else语句效率更高，高于5个分支时switch语句效率更高。

推荐使用System.arraycopy拷贝数组，也可以使用Arrays.copyOf拷贝数组。

SRE: Site Reliability Engineering

API批量服务能力：批量的服务能力，提升整体服务性能。

这里解释下上图中CPU内部集成的存储单元SRAM ，正好和主存中的DRAM对应， RAM 是随机访问内存，就是给一个地址就能访问到数据，而磁盘这种存储媒介必须顺序访问，而RAM又分为动态和静态两种，静态RAM 由于集成度较低，一般容量小，速度快，而动态RAM集成度较高，主要通过给电容充电和放电实现，速度没有静态RAM快，所以一般将动态RAM做为主存，而静态RAM作为 CPU和主存之间的高速缓存（cache），用来屏蔽CPU和主存速度上的差异，也就是我们经常看到的L1，L2缓存。每一级别缓存速度变低，容量变大。

JVM为了提高运行效率也可以将某些热点代码(一个方法内的代码)一次全部编译成机器指令后然后再执行，也就是和解释执行对应的即时编译(JIT)，JVM启动的时候可以通过-Xint和-Xcomp来控制执行模式。

在保护模式下，每一个进程都有自己的独立的地址空间，所以段基地址是固定的，只需要给出段内偏移地址就可以了，而这个偏移地址称为线性地址，线性地址是连续的，而内存将连续的线性地址和分页后的物理地址相关联，这样逻辑上的连续线性地址可以对应不连续的物理地址。
物理地址空间可以被多个进程共享，而这个映射关系将通过页表（ page table）进行维护。 标准页的尺寸一般为 4KB ，分页后，物理内存被分成若干个 4KB 的数据页，进程申请内存的时候，可以映射为多个 4KB 大小的物理内存，而应用程序读取数据的时候会以页为最小单位，当需要和硬盘发生交换的时候也是以页为单位。
因为他是独占的，也保护了各自进程不被其他进程破坏，另外，他把主存看成磁盘的一个缓存，主存中仅保存活动的程序段和数据段，当主存中不存在数据的时候发生缺页中断，然后从磁盘加载进来，当物理内存不足的时候会发生 swap 到磁盘。页表保存了虚拟地址和物理地址的映射，页表是一个数组，每个元素为一个页的映射关系，这个映射关系可能是和主存地址，也可能和磁盘，页表存储在主存，我们将存储在高速缓冲区 cache  中的页表称为快表 TLAB 。

在Java中，使用MappedByteBuffer来实现内存映射，这是一个堆外内存，在映射完之后，并没有立即占用物理内存，而是访问数据页的时候，先查页表，发现还没加载，发起缺页异常，然后在从磁盘将数据加载进内存，所以一些实时性要求很高的中间件，例如rocketmq,消息存储在一个大小1G的文件中，为了加快读写速度，会将这个文件映射到内存后，在每个页写一比特数据，这样就可以把整个1G文件都加载进内存，在实际读写的时候就不会发生缺页了，这个在rocketmq内部叫做文件预热。

JVM 为了内存对齐，会对字段进行重排序，这里的对齐主要指  Java  虚拟机堆中的对象的起始地址为 8 的倍数，如果一个对象用不到 8N 个字节，那么剩下的就会被填充，另外子类继承的属性的偏移量和父类一致，以 Long 为例，他只有一个非 static 属性 value ，而尽管对象头只占有 12 字节，而属性 value 的偏移量只能是 16， 其中 4 字节只能浪费掉，所以字段重排就是为了避免内存浪费， 所以我们很难在 Java 字节码被加载之前分析出这个 Java 对象占有的实际空间有多大，我们只能通过递归父类的所有属性来预估对象大小，而真实占用的大小可以通过  Java agent 中的 Instrumentation获取。
当然内存对齐另外一个原因是为了让字段只出现在同一个CPU的缓存行中，如果字段不对齐，就有可能出现一个字段的一部分在缓存行 1中，而剩下的一半在缓存行2 中，这样该字段的读取需要替换两个缓存行，而字段的写入会导致两个缓存行上缓存的其他数据都无效，这样会影响程序性能。

通过内存对齐可以避免一个字段同时存在两个缓存行里的情况，但还是无法完全规避缓存伪共享的问题，也就是一个缓存行中存了多个变量，而这几个变量在多核 CPU 并行的时候，会导致竞争缓存行的写权限，当其中一个 CPU 写入数据后，这个字段对应的缓存行将失效，导致这个缓存行的其他字段也失效。
在 Disruptor 中，通过填充几个无意义的字段，让对象的大小刚好在 64 字节，一个缓存行的大小为64字节，这样这个缓存行就只会给这一个变量使用，从而避免缓存行伪共享，但是在 jdk7 中，由于无效字段被清除导致该方法失效，只能通过继承父类字段来避免填充字段被优化，而 jdk8 提供了注解@Contended 来标示这个变量或对象将独享一个缓存行，使用这个注解必须在 JVM 启动的时候加上 -XX:-RestrictContended 参数，其实也是用空间换取时间。

按照教科书的定义，进程是资源管理的最小单位，而线程是 CPU 调度执行的最小单位，线程的出现是为了减少进程的上下文切换（线程的上下文切换比进程小很多），以及更好适配多核心 CPU 环境，例如一个进程下多个线程可以分别在不同的 CPU 上执行，而多线程的支持，既可以放在Linux内核实现，也可以在核外实现，如果放在核外，只需要完成运行栈的切换，调度开销小，但是这种方式无法适应多 CPU 环境，底层的进程还是运行在一个 CPU 上，另外由于对用户编程要求高，所以目前主流的操作系统都是在内核支持线程，而在Linux中，线程是一个轻量级进程，只是优化了线程调度的开销。

而在 JVM 中的线程和内核线程是一一对应的，线程的调度完全交给了内核，当调用Thread.run 的时候，就会通过系统调用 fork() 创建一个内核线程，这个方法会在用户态和内核态之间进行切换，性能没有在用户态实现线程高，当然由于直接使用内核线程，所以能够创建的最大线程数也受内核控制。目前 Linux上 的线程模型为 NPTL （ Native POSIX Thread Library），他使用一对一模式，兼容 POSIX 标准，没有使用管理线程，可以更好地在多核 CPU 上运行。

对进程而言，就三种状态，就绪，运行，阻塞，而在 JVM 中，阻塞有四种类型，我们可以通过 jstack 生成 dump 文件查看线程的状态。
	- BLOCKED(on object monitor)通过 synchronized(obj) 同步块获取锁的时候，等待其他线程释放对象锁，dump 文件会显示 waiting to lock <0x00000000e1c9f108>
	- TIMED WAITING(on object monitor)和WAITING(on object monitor)在获取锁后，调用了 object.wait() 等待其他线程调用 object.notify()，两者区别是是否带超时时间
	- TIMED WAITING(sleeping)程序调用了 thread.sleep()，这里如果 sleep(0) 不会进入阻塞状态，会直接从运行转换为就绪
	- TIMED WAITING(parking)和WAITING(parking)程序调用了 Unsafe.park()，线程被挂起，等待某个条件发生，waiting on condition

POSIX 定义了五种同步对象，互斥锁，条件变量，自旋锁，读写锁，信号量，这些对象在 JVM 中也都有对应的实现，并没有全部使用 POSIX 定义的 api，通过 Java 实现灵活性更高，也避免了调用native方法的性能开销，当然底层最终都依赖于 pthread 的 互斥锁 mutex 来实现，这是一个系统调用，开销很大，所以 JVM 对锁做了自动升降级，基于AQS的实现以后在分析，这里主要说一下关键字 synchronized 。
当声明 synchronized 的代码块时，编译而成的字节码会包含一个 monitorenter 和 多个 monitorexit （多个退出路径，正常和异常情况），当执行 monitorenter 的时候会检查目标锁对象的计数器是否为0，如果为0则将锁对象的持有线程设置为自己，然后计数器加1，获取到锁，如果不为0则检查锁对象的持有线程是不是自己，如果是自己就将计数器加1获取锁，如果不是则阻塞等待，退出的时候计数器减1，当减为0的时候清楚锁对象的持有线程标记，可以看出 synchronized 是支持可重入的。

刚刚说到线程的阻塞是一个系统调用，开销大，所以 JVM 设计了自适应自旋锁，就是当没有获取到锁的时候， CPU 回进入自旋状态等待其他线程释放锁，自旋的时间主要看上次等待多长时间获取的锁，例如上次自旋5毫秒没有获取锁，这次就6毫秒，自旋会导致 CPU 空跑，另一个副作用就是不公平的锁机制，因为该线程自旋获取到锁，而其他正在阻塞的线程还在等待。除了自旋锁， JVM 还通过 CAS 实现了轻量级锁和偏向锁来分别针对多个线程在不同时间访问锁和锁仅会被一个线程使用的情况。后两种锁相当于并没有调用底层的信号量实现（通过信号量来控制线程A释放了锁例如调用了 wait()，而线程B就可以获取锁，这个只有内核才能实现，后面两种由于场景里没有竞争所以也就不需要通过底层信号量控制），只是自己在用户空间维护了锁的持有关系，所以更高效。


如上图所示，如果线程进入 monitorenter 会将自己放入该 objectmonitor 的 entryset 队列，然后阻塞，如果当前持有线程调用了 wait 方法，将会释放锁，然后将自己封装成 objectwaiter 放入 objectmonitor 的 waitset 队列，这时候 entryset 队列里的某个线程将会竞争到锁，并进入 active 状态，如果这个线程调用了 notify 方法，将会把 waitset 的第一个 objectwaiter 拿出来放入 entryset （这个时候根据策略可能会先自旋），当调用 notify 的那个线程执行 moniterexit 释放锁的时候， entryset 里的线程就开始竞争锁后进入 active 状态。

LockSupport.park(long nans)   Condition.await()调用的该方法， ScheduledExecutorService 用的 condition.await() 来实现阻塞一定的超时时间，其他带超时参数的方法也都通过他来实现，目前大多定时器都是通过这个方法来实现的，该方法也提供了一个布尔值来确定时间的精度。

抽象工厂(AbstractFactory)模式的定义：是一种为访问类提供一个创建一组相关或互相依赖对象的接口，且访问类无需指定所要产品的具体类就能得到同族的不同等级的产品的模式结构。
抽象工厂模式是工厂方法模式的升级版本，工厂方法模式只生产一个等级的产品，而抽象工厂模式可生产多个等级的产品。
使用抽象工厂模式一般要满足以下条件：
	- 系统中有多个产品族，每个具体工厂创建同一族但属于不同等级结构的产品；
	- 系统一次只可能消费其中某一族产品，即同族的产品一起使用；
抽象工厂模式除了具有工厂方法模式的优点外，其他主要优点如下：
	- 可以在类的内部堆产品族相关联的多等级产品共同管理，而不必专门引入多个新的类来进行管理；
	- 当增加一个新的产品族时不需要修改原代码，满足开闭原则；
其缺点是：当产品族中需要增加一个新的产品时，所有的工厂类都需要进行修改。

抽象工厂模式的应用场景：
	1. 当需要创建的对象是一系列相互关联或相互依赖的产品族时，如电器工厂中的电视机、洗衣机、空调等。
	2. 系统中有多个产品族，但每次只使用其中的某一族产品。如有人只喜欢穿某一个品牌的衣服和鞋。
	3. 系统中提供了产品的类库，且所有产品的接口相同，客户端不依赖产品实例的创建细节和内部结构。

模式的扩展：
抽象工厂模式的扩展有一定的“开闭原则”倾斜性：
	1. 当增加一个新的产品族时只需增加一个新的具体工厂，不需要修改原代码，满足开闭原则。
	2. 当产品族中需要增加一个新种类的产品时，则所有的工厂类都需要进行修改，不满足开闭原则。
另一方面，当系统中只存在一个等级结构的产品时，抽象工厂模式将退化到工厂方法模式。


在性能优化这个领域，并没有一个严格的流程定义，但是对于绝大多数的优化场景，我们可以将其过程抽象为下面四个步骤。
	1. 准备阶段：主要工作是是通过性能测试，了解应用的概况、瓶颈的大概方向，明确优化目标；
	2. 分析阶段：通过各种工具或手段，初步定位性能瓶颈点；
	3. 调优阶段：根据定位到的瓶颈点，进行应用性能调优；
	4. 测试阶段：让调优过的应用进行性能测试，与准备阶段的各项指标进行对比，观测其是否符合预期，如果瓶颈点没有消除或者性能指标不符合预期，则重复步骤2和3。

在进行性能优化时，有以下注意事项：
	1. 性能瓶颈点通常呈现2/8分布，即80%的性能问题通常是由20%的性能瓶颈点导致的，2/8 原则也意味着并不是所有的性能问题都值得去优化；
	2. 性能优化是一个渐进、迭代的过程，需要逐步、动态地进行。记录基准后，每次改变一个变量，引入多个变量会给观测、优化过程造成干扰；
	3. 不要过度追求应用的单机性能，如果单机表现良好，则应该从系统架构的角度去思考；不要过度追求单一维度上的极致优化，如过度追求CPU的性能而忽略了内存方面的瓶颈；
	4. 旋转合适的性能优化工具，可以使得性能优化取得事半功倍的效果；
	5. 整个应用的优化，应该与线上系统隔离，新的代码上线应该有降级方案；

如果瓶颈点在应用层和系统层均呈现多变量分布，建议此时使用ZProfiler, JProfiler等工具对应用进行Profiling, 获取应用的综合性能信息(Profiling指的是在应用运行时，通过事件(Event-based)、统计抽样(Sampling Statistical)或植入附加指令(Byte-Code instrumentattion)等方法，收集应用运行时的信息，来研究应用行为的动态分析方法)。譬如，可以对CPU进行抽样统计，结合各种符号表信息，得到一段时间内的代码热点。

1. CPU利用率: CPU Utilization
2. CPU平均负载: Load Average
3. 上下文切换次数：Context Switch 

使用vmstat命令，可以查看到【上下文切换次数】这个指标，vmstat 1：每隔1秒输出1组数据。
cs：context switch每秒上下文切换的次数，按照不同场景，CPU上下文切换还可以分为中断上下文切换、线程上下文切换和进程上下文切换三种，但是无论是哪一种，过多的上下文切换，都会把CPU时间消耗在寄存器、内核栈以及虚拟内存等数据的保存和恢复上，从而缩短进程真正运行的时间，导致系统的整体性能大幅下降。
vmstat的输出只给出了系统总体的上下文切换情况，要想查看每个进程的上下文切换详情(如自愿和非自愿)，需要使用pidstat，该命令还可以查看某个进程用户态和内核态的CPU利用率。

buff/cache 是缓存和缓冲区的大小。缓存（cache）：是从磁盘读取的文件的或者向磁盘写文件时的临时存储数据，面向文件。使用 cachestat 可以查看整个系统缓存的读写命中情况，使用 cachetop 可以观察每个进程缓存的读写命中情况。缓冲区（buffer）是写入磁盘数据或从磁盘直接读取的数据的临时存储，面向块设备。free 命令的输出中，这两个指标是加在一起的，使用 vmstat 命令可以区分缓存和缓冲区，还可以看到 Swap 分区换入和换出的内存大小。


内存相关指标异常后，分析思路是怎么样的？
	1. 使用 free/top 查看内存的全局使用情况，如系统内存的使用、Swap 分区内存使用、缓存/缓冲区占用情况等，初步判断内存问题存在的方向：进程内存、缓存/缓冲区、Swap 分区；
	2. 观察一段时间内存的使用趋势。如通过 vmstat 观察内存使用是否一直在增长；通过 jmap 定时统计对象内存分布情况，判断是否存在内存泄漏，通过 cachetop 命令，定位缓冲区升高的根源等；
	3. 根据内存问题的类型，结合应用本身，进行详细分析。

举例：使用 free 发现缓存/缓冲区占用不大，排除缓存/缓冲区对内存的影响后 -> 使用 vmstat 或者 sar 观察一下各个进程内存使用变化趋势 -> 发现某个进程的内存时候用持续走高 -> 如果是 Java 应用，可以使用 jmap / VisualVM / heap dump 分析等工具观察对象内存的分配，或者通过 jstat 观察 GC 后的应用内存变化 -> 结合业务场景，定位为内存泄漏/GC参数配置不合理/业务代码异常等。

结构型模式描述如何将类或对象按某种布局组成更大的结构。它分为类结构型模式和对象结构型模式，前者采用继承机制来组织接口和类，后者釆用组合或聚合来组合对象。
由于组合关系或聚合关系比继承关系耦合度低，满足“合成复用原则”，所以对象结构型模式比类结构型模式具有更大的灵活性。
结构型模式分为以下 7 种：
	1. 代理（Proxy）模式：为某对象提供一种代理以控制对该对象的访问。即客户端通过代理间接地访问该对象，从而限制、增强或修改该对象的一些特性。
	2. 适配器（Adapter）模式：将一个类的接口转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类能一起工作。
	3. 桥接（Bridge）模式：将抽象与实现分离，使它们可以独立变化。它是用组合关系代替继承关系来实现的，从而降低了抽象和实现这两个可变维度的耦合度。
	4. 装饰（Decorator）模式：动态地给对象增加一些职责，即增加其额外的功能。
	5. 外观（Facade）模式：为多个复杂的子系统提供一个一致的接口，使这些子系统更加容易被访问。
	6. 享元（Flyweight）模式：运用共享技术来有效地支持大量细粒度对象的复用。
	7. 组合（Composite）模式：将对象组合成树状层次结构，使用户对单个对象和组合对象具有一致的访问性。
以上 7 种结构型模式，除了适配器模式分为类结构型模式和对象结构型模式两种，其他的全部属于对象结构型模式。


综上，没有结构化编程，程序就无法从一块块可证伪的逻辑搭建，没有面向对象编程，跨越组件边界是一个非常麻烦而危险的过程，而函数式编程，让组件更加高效而稳定。没有编程范式，架构设计将无从谈起。

和编程范式(结构化编程、面向对象编程、函数式编程)相比，进行架构设计的主导原则是OCP(开闭原则)，在类和代码的层级上有：SRP(单一职责原则)、LSP(里氏替换原则)、ISP(接口隔离原则)、DIP(依赖倒转原则)；在组件的层级上有：REP(复用、发布等同原则)、CCP(共同闭包原则)、CRP(共同复用原则)，处理组件依赖问题的三原则：无依赖环原则、稳定依赖原则、稳定抽象原则。

----------------------------------------------------------------------------------------
REP: 复用、发布等同原则
	软件复用的最小粒度应等同于其发布的最小粒度。直白地说，就是要复用一段代码就把它抽成组件。该原则指导我们组件拆分的粒度。
CCP：共同闭包原则
	为了相同目的而同时修改的类，应该放在同一个组件中。CCP 原则是 SRP 原则在组件层面的描述。该原则指导我们组件拆分的粒度。
	对大部分应用程序而言，可维护性的重要性远远大于可复用性，由同一个原因引起的代码修改，最好在同一个组件中，如果分散在多个组件中，那么开发、提交、部署的成本都会上升。
CRP：共同复用原则
	不要强迫一个组件依赖它不需要的东西。CRP 原则是 ISP 原则在组件层面的描述。该原则指导我们组件拆分的粒度。
	相信你一定有这种经历，集成了组件A，但组件A依赖了组件B、C。即使组件B、C 你完全用不到，也不得不集成进来。这是因为你只用到了组件A的部分能力，组件A中额外的能力带来了额外的依赖。如果遵循共同复用原则，你需要把A拆分，只保留你要用的部分。

REP、CCP、CRP 三个原则之间存在彼此竞争的关系，REP 和 CCP 是黏合性原则，它们会让组件变得更大，而 CRP 原则是排除性原则，它会让组件变小。遵守REP、CCP 而忽略 CRP ，就会依赖了太多没有用到的组件和类，而这些组件或类的变动会导致你自己的组件进行太多不必要的发布；遵守 REP 、CRP 而忽略 CCP，因为组件拆分的太细了，一个需求变更可能要改n个组件，带来的成本也是巨大的。
	优秀的架构师应该能在上述三角形张力区域中定位一个最适合目前研发团队状态的位置，例如在项目早期，CCP比REP更重要，随着项目的发展，这个最合适的位置也要不停调整。
----------------------------------------------------------------------------------------
协程是属于线程的，又称微线程，纤程，英文名Coroutine。举个例子，在执行函数A时，我希望随时中断去执行函数B，然后中断B的执行，切换回来执行A。这就是协程的作用，由调用者自由切换。这个切换过程并不是等同于函数调用，因为它没有调用语句。执行方式与多线程类似，但是协程只有一个线程执行。
协程的优点是执行效率非常高，因为协程的切换由程序自身控制，不需要切换线程，即没有切换线程的开销。同时，由于只有一个线程，不存在冲突问题，不需要依赖锁(加锁与释放锁存在很多资源消耗)。
协程主要的使用场景在于处理IO密集型程序，解决效率问题，不适用于CPU密集型程序的处理。然而实际场景中这两种场景非常多，如果要充分发挥CPU利用率，可以结合多进程+协程的方式。后续我们会讲到结合点。
根据wikipedia的定义，协程是一个无优先级的子程序调度组件，允许子程序在特定的地方挂起恢复。所以理论上，只要内存足够，一个线程中可以有任意多个协程，但同一时刻只能有一个协程在运行，多个协程分享该线程分配到的计算机资源。协程是为了充分发挥异步调用的优势，异步操作则是为了避免IO操作阻塞线程。
----------------------------------------------------------------------------------------
桥接模式的优点：
	- 由于抽象与实现分离，所以扩展能力强；
	- 其实现细节对客户透明；
缺点是：由于聚合关系建立在抽象层，要求开发者针对抽象化进行设计与编程，这增加了系统的理解与设计难度。
桥接模式的结构：可以将抽象化部分与实现化部分分开，取消二者的继承关系，改用组合关系。
桥接模式包含以下主要角色：
	1. 抽象化角色Abstraction: 定义抽象类，并包含一个对实现化对象的引用；
	2. 扩展抽象化角色Refined Abstraction:是抽象化角色的子类，实现父类中的业务方法，并通过组合关系调用实现化角色中的业务方法；
	3. 实现化角色Implementor：定义实现化角色的接口，供扩展抽象化角色调用；
	4. 具体实现化角色Concrete Implementor:给出实现化角色接口的具体实现。
桥接模式的应用场景：
	1. 当一个类存在两个独立变化的维度，且这两个维度都需要进行扩展时。
	2. 当一个系统不希望使用继承或因为多层次继承导致系统类的个数急剧增加时。
	3. 当一个系统需要在构件的抽象化角色和具体化角色之间增加更多的灵活性时

桥接模式的扩展：在软件开发中，有时桥接模式可与适配器模式联合使用。当桥接模式的实现化角色的接口与现有类的接口不一致时，可以在两者中间定义一个适配器将两者连接起来。

Kubernetes 集群管理系统需要具备便捷的集群生命周期管理能力，完成集群的创建、升级和工作节点的管理。在大规模场景下，集群变更的可控性直接关系到集群的稳定性，因此管理系统可监控、可灰度、可回滚的能力是系统设计的重点之一。
除此之外，超大规模集群中，节点数量已经达到 10K 量级，节点硬件故障、组件异常等问题会常态出现。面向大规模集群的管理系统在设计之初就需要充分考虑这些异常场景，并能够从这些异常场景中自恢复。

外观模式是迪米特法则的典型应用，主要优点如下：
	1. 降低了子系统与客户端之间的耦合度，使得子系统的变化不会影响调用它的客户类；
	2. 对客户端屏蔽了子系统组件，减少了客户处理的对象数目，并使得子系统使用起来更加容易；
	3. 降低了大型软件系统中的编译依赖性，简化了系统在不同平台之间的移植过程，因为编译一个子系统不会影响其他的子系统，也不会影响外观对象；
外观模式的主要缺点如下：
	1. 不能很好地限制客户使用子系统类；
	2. 增加新的子系统可能需要修改外观类或客户端的原代码，违背了开闭原则；

外观模式的扩展：
	在外观模式中，当增加或移除子系统时需要修改外观类，这违背了开闭原则。如果引入抽象外观类，则在一定程度上解决了该问题。

享元模式的优点：相同对象只要保存一份，降低了系统中对象的数量，从而降低了系统中细粒度对象给内存带来的压力。
享元模式的缺点：
	1. 为了使对象可以共享，需要将一些不能共享的状态外部化，这将增加程序的复杂性；
	2. 读取享元模式的外部状态会使得运行时间稍微变长。

享元模式的主要角色有如下。
	1. 抽象享元角色(Flyweight):是所有的具体享元类的基类，为具体享元规范需要实现的公共接口，非享元的外部状态以参数的形式通过方法传入。
	2. 具体享元角色(ConcreteFlyweight)：实现抽象享元角色中所规定的接口。
	3. 非享元角色(UnsharableFlyweight)：是不可以共享的外部状态，它以参数的形式注入具体享元的相关方法中。
	4. 享元工厂角色(FlyweightFactory)：负责创建和管理享元角色。当客户对象请求一个享元对象时，享元工厂检査系统中是否存在符合要求的享元对象，如果存在则提供给客户；如果不存在的话，则创建一个新的享元对象。

享元模式的扩展：在享元模式的结构图中包含可以共享的部分和不可以共享的部分。在实际使用过程中，有时候会稍加改变，即存在两种特殊的享元模式：单纯享元模式和复合享元模式。
	1. 单纯享元模式：这种享元模式中的所有具体的享元类都是可以共享的，不存在非共享的具体享元类；
	2. 复合享元模式：这种享元模式中的有些享元是由一些单纯享元对象组合而成的，它们就是复合享元对象，虽然复合享元对象本身不能共享，但它们可以分解成单纯享元对象再被共享。

组合模式Composite定义：又叫做部分-整体模式，是一种将对象组合成树状的层次结构的模式，用来表示"部分-整体"的关系，使用户对单个对象和组合对象具有一致的访问性。
组合模式的优点：
	1. 组合模式使得客户端代码可以一致地处理单个对象和组合对象，无须关心自己处理的是单个对象，还是组合对象，简化了客户端代码；
	2. 更容易在组合体内加入新的对象，客户端不会因为加入了新的对象而更改源代码，满足开闭原则；
组合模式的缺点：
	1. 设计较复杂，客户端需要花更多时间理清类之间的层次关系；
	2. 不容易限制容器中的构件；
	3. 不容易用继承的方法来增加构件的新功能；
组合模式包含以下主要角色。
	1. 抽象构件（Component）角色：它的主要作用是为树叶构件和树枝构件声明公共接口，并实现它们的默认行为。在透明式的组合模式中抽象构件还声明访问和管理子类的接口；在安全式的组合模式中不声明访问和管理子类的接口，管理工作由树枝构件完成。
	2. 树叶构件（Leaf）角色：是组合中的叶节点对象，它没有子节点，用于实现抽象构件角色中 声明的公共接口。
	3. 树枝构件（Composite）角色：是组合中的分支节点对象，它有子节点。它实现了抽象构件角色中声明的接口，它的主要作用是存储和管理子部件，通常包含 Add()、Remove()、GetChild() 等方法。

组合模式分为透明式的组合模式和安全式的组合模式。
	1. 透明方式：在该方式中，由于抽象构件声明了所有子类中的全部方法，所以客户端无须区别树叶对象和树枝对象，对客户端来说是透明的。但缺点是：树叶构件本来没有add,remove,getChild方法，却要实现它们(空实现或者抛异常)，这样会带来一些安全性问题。
	2. 安全方式：在该方式中，将管理子构件的方法移到树枝构件中，抽象构件和树叶构件没有对子对象的管理方法，这样就避免了上一种方式的安全性问题，但由于叶子和分支有不同的接口，客户端在调用时要知道树叶对象和树枝对象的存在，失去了透明性。

组合模式的扩展：如果对组合模式中的树叶节点和树枝节点进行抽象，也就是树叶节点和树枝节点还有子节点，这时组合模式就扩展成复杂的组合模式了。

----------------------------------------------------
行为型模式用于描述程序在运行时复杂的流程控制，即描述多个类或对象之间怎样相互协作共同完成单个对象都无法单独完成的任务，它涉及算法与对象间职责的分配。

行为型模式分为类行为模式和对象行为模式，前者采用继承机制来在类间分派行为，后者采用组合或聚合在对象间分配行为。由于组合关系或聚合关系比继承关系耦合度低，满足“合成复用原则”，所以对象行为模式比类行为模式具有更大的灵活性。

行为型模式是 GoF 设计模式中最为庞大的一类，它包含以下 11 种模式。
模板方法（Template Method）模式：定义一个操作中的算法骨架，将算法的一些步骤延迟到子类中，使得子类在可以不改变该算法结构的情况下重定义该算法的某些特定步骤。
策略（Strategy）模式：定义了一系列算法，并将每个算法封装起来，使它们可以相互替换，且算法的改变不会影响使用算法的客户。
命令（Command）模式：将一个请求封装为一个对象，使发出请求的责任和执行请求的责任分割开。
职责链（Chain of Responsibility）模式：把请求从链中的一个对象传到下一个对象，直到请求被响应为止。通过这种方式去除对象之间的耦合。
状态（State）模式：允许一个对象在其内部状态发生改变时改变其行为能力。
观察者（Observer）模式：多个对象间存在一对多关系，当一个对象发生改变时，把这种改变通知给其他多个对象，从而影响其他对象的行为。
中介者（Mediator）模式：定义一个中介对象来简化原有对象之间的交互关系，降低系统中对象间的耦合度，使原有对象之间不必相互了解。
迭代器（Iterator）模式：提供一种方法来顺序访问聚合对象中的一系列数据，而不暴露聚合对象的内部表示。
访问者（Visitor）模式：在不改变集合元素的前提下，为一个集合中的每个元素提供多种访问方式，即每个元素有多个访问者对象访问。
备忘录（Memento）模式：在不破坏封装性的前提下，获取并保存一个对象的内部状态，以便以后恢复它。
解释器（Interpreter）模式：提供如何定义语言的文法，以及对语言句子的解释方法，即解释器。
以上 11 种行为型模式，除了模板方法模式和解释器模式是类行为型模式，其他的全部属于对象行为型模式，
----------------------------------------------------
使用过程分解之后的代码，已经比以前的代码更清晰、更容易维护了。不过，还有两个问题值得关注：
	1. 领域知识被割裂肢解：什么叫被肢解?目前为止做的都是过程化拆解，导致没有一个聚合领域知识的地方。每个Use Case的代码只关心自己的处理流程，知识没有沉淀。
		相同的业务逻辑会在Use Case中被重复实现，导致代码重复度高，即时有复用，最多也就是抽取一个util，代码对业务语义的表达能力很弱，从而影响代码的可读性和可理解性。
	2. 代码的业务表达能力缺少：试想下，在过程式的代码中，所做的事情无外乎就是取数据--做计算--存数据，在这种情况下，要如何通过代码显性化的表达我们的业务呢？说实话，很难做到，因为我们缺失了模型，以及模型之间的关系。脱离模型的业务表达，是缺少韵律和灵魂的。

自上而下的结构化分解+自下而上的面向对象分析;
----------------------------------------------------------
模板方法(TemplateMethod)模式的定义如下:定义一个操作中的算法骨架，而将算法的一些步骤延迟到子类中，使得子类可以不改变算法结构的情况下重定义该算法的特殊步骤。它是一种类行为模式。
模板方法的优点：
	1. 封装了不变部分，扩展可变部分。它把认为是不变部分的算法封装到父类中实现，而把可变部分算法由子类继承实现，便于子类继续扩展；
	2. 它在父类中提取了公共的部分代码，便于代码复用；
	3. 部分方法是由子类实现的，因此子类可以通过扩展方式增加相应的功能，符合开闭原则；

模板方法的缺点：
	1. 对每个不同的实现都需要定义一个子类，这会导致类的个数增加，系统更加庞大，设计也更抽象；
	2. 父类中的抽象方法由子类实现，子类执行的结果会影响父类的结果，这导致一种反向的控制结构，它增加了代码阅读的难度；
	
模板方法模式包含以下主要角色。
(1) 抽象类（Abstract Class）：负责给出一个算法的轮廓和骨架。它由一个模板方法和若干个基本方法构成。这些方法的定义如下。
	1. 模板方法：定义了算法的骨架，按某种顺序调用其包含的基本方法。
	2. 基本方法：是整个算法中的一个步骤，包含以下几种类型。
	抽象方法：在抽象类中申明，由具体子类实现。
	具体方法：在抽象类中已经实现，在具体子类中可以继承或重写它。
	钩子方法：在抽象类中已经实现，包括用于判断的逻辑方法和需要子类重写的空方法两种。
(2) 具体子类（Concrete Class）：实现抽象类中所定义的抽象方法和钩子方法，它们是一个顶级逻辑的一个组成步骤。

模板方法模式的扩展：在模板方法模式中，基本方法包含：抽象方法、具体方法和钩子方法，正确使用钩子方法，可以使得子类控制父类的行为。
----------------------------------------------------------
Cannot reduce the visibility of the inherited method.

策略模式的定义：该模式定义了一系列算法，并将每个算法封装起来，使它们可以相互替换，且算法的变化不会影响使用算法的客户。策略模式属于对象行为模式，它通过对算法进行封装，把使用算法的责任和算法的实现分割开来，并委派给不同的对象对这些算法进行管理。
策略模式的主要优点如下：
	1. 多重条件语句不易维护，而使用策略模式可以避免使用多重条件语句；
	2. 策略模式提供了一些列的可供重用的算法族，恰当使用继承可以把算法族的公共代码转移到父类里面，从而避免重复的代码；
	3. 策略模式可以提供相同行为的不同实现，客户可以根据不同时间或空间要求选择不同的策略；
	4. 策略模式提供了对开闭原则的完美支持，可以在不修改原代码的情况下，灵活增加新算法；
	5. 策略模式把算法的使用放在环境类中，而算法的实现移到具体策略类中，实现了两者的分离；
策略模式的缺点：
	1. 客户端必须理解所有策略算法的区别，以便适时选择恰当的算法类；
	2. 策略模式造成很多的策略类；
策略模式的扩展：在使用一个策略模式的系统中，当存在的策略很多时，客户端管理所有策略算法将变得很复杂，如果在环境类中使用策略工厂模式来管理这些策略类，将大大减少客户端的工作复杂度。

命令模式：将一个请求封装为一个对象，使发出请求的责任和执行请求的责任分割开。这样两者之间通过命令对象进行沟通，这样方便将命令对象进行存储、传递、调用、增加和管理。
命令模式的优点：
	1. 降低系统的耦合度。命令模式能将调用操作的对象与实现该操作的对象解耦；
	2. 增加或删除命令非常方便。采用命令模式增加或删除命令不会影响其他类，满足开闭原则，对扩展比较灵活；
	3. 可以实现宏命令。命令模式可以和组合模式结合，将多个命令装配称一个组合命令，即宏命令；
	4. 方便实现Undo和Redo操作。命令模式可以和备忘录模式结合，实现命令的撤销与恢复。
命令模式的缺点：可能产生大量命令类。因为针对每一个具体操作都需要设计一个具体命令类，这将增加系统的复杂性。
命令模式的扩展：在软件开发中，有时将命令模式与组合模式联合使用，构成了宏命令模式，也叫组合命令模式。宏命令包含了一组命令，它充当了具体命令与调用者的双重角色，执行它时将递归调用它所包含的所有命令。

责任链：也叫职责链，为了避免请求发送者与多个请求处理者耦合在一起，将所有请求的处理者通过前一对象记住其下一对象的引用而连成一条链；当有请求发生时，可将请求沿着这条链传递，直到有对象处理它为止。
在责任链模式中，客户只需要将请求发送到责任链上即可，无须关心请求的处理细节和请求的传递过程，所以责任链将请求的发送者和请求的处理者解耦了。
责任链是一种对象行为型模式，其优点如下：
	1. 降低了对象之间的耦合度。该模式使得一个对象无须知道到底是哪一个对象处理其请求以及链的结构，发送者和接收者也无须拥有对方的明确信息。
	2. 增强了系统的可扩展性。可以根据需要增加新的请求处理类，满足开闭原则。
	3. 增强了给对象指派职责的灵活性。当工作流程发生变化，可以动态地改变链内的成员或者调动它们的次序，也可动态地新增或者删除责任。
	4. 责任链简化了对象之间的连接。每个对象只需保持一个指向其后继者的引用，不需保持其他所有处理者的引用，这避免了使用众多的 if 或者 if···else 语句。
	5. 责任分担。每个类只需要处理自己该处理的工作，不该处理的传递给下一个对象完成，明确各类的责任范围，符合类的单一职责原则。
责任链的缺点：
	1. 不能保证每个请求一定被处理。由于一个请求没有明确的接收者，所以不能保证它一定会被处理，该请求可能一直传到链的末端都得不到处理。
	2. 对比较长的职责链，请求的处理可能涉及多个处理对象，系统性能将受到一定影响。
	3. 职责链建立的合理性要靠客户端来保证，增加了客户端的复杂性，可能会由于职责链的错误设置而导致系统出错，如可能会造成循环调用。

责任链的扩展：存在以下两种情况：
	1. 纯的职责链模式：一个请求必须被某一个处理者对象所接收，且一个具体处理者对某个请求的处理只能采用以下两种行为之一：自己处理；把责任推给下家；
	2. 不纯的职责链：允许出现某一个具体处理者对象承担了请求的一部分责任又将剩余的责任传给下家的情况，且一个请求可以最终不被任何处理者所处理。
------------------------------------------------------
状态模式:State，对有状态的对象，把复杂的判断逻辑提取到不同的状态对象中，允许状态对象在其内部状态发生改变时改变其行为。
状态模式是一种对象行为型模式，优点如下：
	1. 状态模式与特定状态相关的行为局部化到一个状态中，并且将不同状态的行为分割开来，满足单一职责原则；
	2. 减少对象间的互相依赖。将不同钻沟通引入独立的对象中会使得状态转换变得更加明确，且减少对象间的互相依赖；
	3. 有利于程序的扩展。通过定义新的子类很容易地增加新的状态和转换；
缺点：
	1. 状态模式的使用必然会增加系统的类与对象的个数；
	2. 状态模式的结构与实现都较为复杂，如果使用不当会导致程序结构和代码的混乱。
状态模式的扩展：在有些情况下，可能多个环境对象需要共享一组状态，这时需要引入享元模式，将这些具体状态对象放在集合中供程序共享。分析：共享状态模式的不同之处是在环境类中增加了一个HashMap来保存相关状态，当需要某种状态时可以从中获取。
------------------------------------------------------
观察者模式：Observer，指多个对象间存在一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。这种模式有时又称做发布订阅模式、模型-视图模式，它是对象行为型模式；
优点：
	1. 降低了目标与观察者之间的耦合关系，两者之间是抽象耦合关系；
	2. 目标与观察者之间建立了一套触发机制。
缺点：
	1. 目标与观察者之间的依赖关系并没有完全解除，而且有可能出现循环引用；
	2. 当观察者对象很多时，通知的发布会 花费很多时间，影响程序的效率；
观察者模式的扩展：通过java.util.Observable类和java.util.Observer接口定义了观察者模式，只要实现它们的子类就可以编写观察者模式实例。
	1. Observable类
		Observable类是抽象目标类，它有一个Vector向量，用于保存所有要通知的观察者对象，下面来介绍它最重要的3个方法。
			void addObserver(Observer o)：用于将新的观察者对象添加到向量中。
			void notifyObservers(Object arg)：调用向量中的所有观察者对象的update方法，通知它们数据发生改变。通常越晚加入向量的观察者越先得到通知。
			void setChange()：用来设置一个boolean类型的内部标志位，注明目标对象发生了变化。当它为真时，notifyObservers()才会通知观察者。
	2. Observer 接口
	Observer接口是抽象观察者，它监视目标对象的变化，当目标对象发生变化时，观察者得到通知，并调用void update(Observable o,Object arg) 方法，进行相应的工作。
------------------------------------------------------
中介者模式：定义一个中介对象来封装一系列对象之间的交互，使原有对象之间的耦合松散，且可以独立地改变它们之间的交互。中介者模式又叫做调停模式，它是迪米特法则的典型应用。
中介者模式是对象行为型模式，优点如下：
	1. 降低了对象之间的耦合性，使得对象易于独立地被复用；
	2. 将对象间的一对多关联转变为一对一的关联，提高系统的灵活性，使得系统易于维护和扩展；
缺点：当同事类太多时，中介者的职责将很大，它会变得复杂而庞大，以至于系统难以维护。
中介者模式的扩展：在实际开发中，通常采用以下两种方法来简化中介者模式，使开发变得更简单。
	1. 不定义中介者接口，把具体中介者对象实现为单例；
	2. 同事对象不持有中介者，而是在需要的时候直接获取中介者对象并调用；
------------------------------------------------------
迭代器模式：提供一个对象来顺序访问聚合对象中的一系列数据，而不暴露聚合对象的内部表示。迭代器模式是一种对象行为型模式。
优点：
	1. 访问一个聚合对象的内容而无须暴露它的内部表示；
	2. 遍历任务交由迭代器完成，这简化了聚合类；
	3. 它支持不同方式遍历聚合对象，甚至可以自定义迭代器的子类以支持新的遍历；
	4. 增加新的聚合类和迭代器类都很方便，无须修改原有代码；
	5. 封装性良好，为遍历不同的聚合结构提供一个统一的接口。
缺点：增加了类的个数，这在一定程度上增加了系统的复杂性。
迭代器模式的扩展：迭代器模式常常与组合模式结合起来使用，在对组合模式中的容器构件进行访问时，经常将迭代器潜藏在组合模式的容器构成类中。当然，也可以构造一个外部迭代器来对容器构件进行访问。
------------------------------------------------------
访问者模式：Vistor将作用于某种数据结构中的各元素的操作分离出来封装称独立的类，使其在不改变数据结构的前提下可以添加作用于这些元素的新操作，为数据结构中的每个元素提供多种访问方式。它对数据的操作与数据结构进行分离，是行为型模式中最复杂的一种模式。
访问者模式是对象行为型模式，优点如下：
	1. 扩展性好。能够在不修改对象结构中的元素的情况下，为对象结构中的元素添加新功能；
	2. 复用性好。可以通过访问者来定义整个对象结构通用的功能，从而提高系统的复用程度；
	3. 灵活性好。访问者模式将数据结构与作用于结构上的操作解耦，使得操作集合可相对自由地演化而不影响系统的数据结构；
	4. 符合单一职责原则。访问者模式把相关的行为封装在一起，构成一个访问者，使每个访问者的功能都比较单一；
缺点： 
	1. 增加新的元素类很困难。在访问者模式中，每增加一个新的元素类，都要在每一个具体访问者类中增加相应的具体操作，这违背了开闭原则；
	2. 破坏封装。访问者模式中具体元素对访问者公布细节，这破坏了对象的封装性；
	3. 违反了依赖倒置原则。访问者模式依赖了具体类，而没有依赖抽象类。
访问者模式的扩展：Visitor是使用频率较高的设计模式，常常和以下两种设计模式联用。
	1. 与迭代器模式联用。因为访问者模式中的对象结构是一个包含元素角色的容器，当访问者遍历容器中的所有元素时，常常要用迭代器；
	2. 同组合模式联用。因为访问者中的元素对象可能是叶子对象或者组合对象，如果元素对象包含组合对象，就必须用组合模式。
------------------------------------------------------
备忘录Memento:在不破坏封装性的前提下，获取对象的内部状态，并在该对象之外保存这个状态，以便以后需要时能将该对象恢复到原先保存的状态。又叫做快照模式。
备忘录模式是对象行为型模式，优点：
	1. 提供了一种可以恢复状态的机制。当用户需要时能够比较方便地将数据恢复到某个历史状态；
	2. 实现了内部状态的封装。除了创建它的发起人之外，其他对象都不能访问这些状态信息；
	3. 简化了发起人角色，发起人不需要管理和保存其内部状态的各个备份，所有状态信息都保存在备忘录中，并由管理者进行管理，这符合单一职责原则；
缺点：资源消耗大，如果要保存的内部状态信息过多或者太过频繁，将会占用较大的内存资源。
备忘录模式的扩展：在前面介绍的备忘录模式中，有单状态备份的例子，也有多状态备份的例子。下面介绍备忘录模式如何同原型模式混合使用。在备忘录模式中，通过定义“备忘录”来备份“发起人”的信息，而原型模式的 clone() 方法具有自备份功能，所以，如果让发起人实现 Cloneable 接口就有备份自己的功能，这时可以删除备忘录类
------------------------------------------------------
解释器模式：Interpreter给分析对象定义一个语言，并定义该语言的文法表示，再设计一个解析器来解释语言中的句子。也就是说用编译语言的方式来分析应用中的实例。这种模式实现了文法表达式处理的接口，该接口解释一个特定的上下文。
解释器模式是一种类行为型模式，优点如下：	
	1. 扩展性好。由于在解释器模式中使用类来表示语言的文法规则，因此可以通过继承等机制来改变或扩展文法；
	2. 容易实现。在语法树中的每个表达式节点类都是类似的，所以实现其文法较为容易；
缺点： 
	1. 执行效率较低。解释器模式中通常使用大量的循环和递归调用，当要解释的句子较复杂时，其运行速度很慢，且代码的调试过程麻烦；
	2. 会引起类膨胀。解释器模式中的每条规则至少需要定义一个类，当包含的文法规则很多时，类的个数将急剧增加，导致系统难以管理与维护；
	3. 可应用的场景较少。在软件开发中，需要定义语言文法的应用实例非常少，所以这种模式很少被使用到。
解释器模式的结构与组合模式类似，不过其包含的组成元素比组合模式多，而且组合模式是对象结构型模式，而解释器模式是类行为型模式。
解释器模式的扩展：在项目开发中，如果要对数据表达式进行分析与计算，无须再用解释器模式进行设计了，Java 提供了以下强大的数学公式解析器：Expression4J、MESP(Math Expression String Parser) 和 Jep 等，它们可以解释一些复杂的文法，功能强大，使用简单。
现在以 Jep 为例来介绍该工具包的使用方法。Jep 是 Java expression parser 的简称，即 Java 表达式分析器，它是一个用来转换和计算数学表达式的 Java 库。通过这个程序库，用户可以以字符串的形式输入一个任意的公式，然后快速地计算出其结果。而且 Jep 支持用户自定义变量、常量和函数，它包括许多常用的数学函数和常量。
------------------------------------------------------
在软件系统中，类不是孤立存在的，类与类之间存在各种关系。根据类与类之间的耦合度从弱到强排列，有依赖关系、关联关系、聚合关系、组合关系、泛化关系和实现关系等6种。

怎么实现分布式缓存？
	1. 雪崩问题防范；
	2. Cache和DB的一致性；
	3. 缓存中间件的选择；
	4. 缓存穿透问题防范；
	5. 高可用性，无单点故障；
	6. 横向扩展性，数据分片策略，扩容/缩容策略；
	7. Cache的主从之间的延时问题；
	8. 相关的监控机制，检测方案，健康检查机制；
	9. 相关的回滚方案；
	10. 相关的降级方案；
	11. 淘汰策略；
	12. 热点数据的不平衡问题；
	13. 缓存击穿问题防范；
	14. 多层次；这样某一层挂了，还有另一层可以撑着，等待缓存的修复，例如分布式缓存因为某种原因挂了，因为持久化的原因/同步机制的原因/内存过大的原因等，修复需要一段时间，至少本地缓存可以扛一阵，不至于一下子就击穿数据库。而且对于特别热的数据，热到集中式的缓存处理不过来，网卡也打满的情况，由于本地缓存不需要远程调用，也是分布在应用层的，可以缓解这种问题。


缓存的更新模式：
	1. Cache Aside模式；
		- 读取失效：cache数据没有命中，查询DB，成功后把数据写入缓存；
		- 读取命中：读取cache数据；
		- 更新：把数据更新到DB，失效缓存；
		为什么更新不直接写缓存？为了防止高并发的数据不一致；
	2. Read/Write Through模式；
		- 缓存代理了DB读取、写入的逻辑，可以把缓存看作唯一的存储；
	3. Write Behind Caching(Write Back)模式；
		- 这种模式下所有的操作都走缓存，缓存里的数据再通过异步的方式同步到数据库里。所以系统的写性能大大提升了。
	
缓存的三大矛盾问题：
	1. 缓存实时性和一致性问题：当有写入后怎么处理；
	2. 缓存的穿透问题：当缓存没有读到数据怎么处理；
	3. 缓存对数据库高并发访问：都来访问数据库怎么处理；

自底向上推导应用逻辑架构
自顶向下构建架构
升层思考问题，升维思考手段/方法。不过这张图中每个问题到底严重到什么程度，还没有给出量化，不过我们在工作中，我们是要量化这个严重程度，而且要放在时间轴上来进行量化，因为有些问题当前可能并不严重，但是数月后可能会变成大问题。

Nmon:开源性能监控工具，用于监控Linux系统的资源消耗信息，并能把结果输出到文件中，然后通过nmon_analyser工具产生数据文件与图形化结果。

不是swap空间占用多就一定性能下降，真正影响性能是swap in和out的频率，频率越高，对系统的性能影响越大。
使用vmstat监控swap in和swap out。
Swap Used高，可能的情况：Swap和GC同时发生会导致GC时间变长，可以通过减少堆大小，或者增加物理内存解决。加入GC的时候，有堆的一部分内存被交换到swap，GC时内存空间不足，就需要把内存中堆的另外一部分换到swap，Linux对swap的回收是滞后的，就会看到大量swap占用。




常见的监控指标：
	1. 通用监控指标：
		1.1 CPU 
		1.2 内存 
		1.3 硬盘：磁盘IO速度、传输、读写比率
		1.4 文件系统 
		1.5 NFS
		1.6 高耗进程(资源占用率比较高的进程)
		1.7 虚拟内存 
		1.8 Swap Space交换空间
		1.9 负载
		1.10 文件句柄数
	2. 数据库监控指标：
		2.1 缓存命中 
		2.2 索引
		2.3 慢SQL
		2.4 数据库线程数
		2.5 连接池
	3. 中间件监控指标：
		3.1 消息累积
		3.2 消息追踪
		3.3 消息调用链
		3.4 负载均衡
		3.5 缓存
	4. 网络：
		4.1 吞吐量
		4.2 吞吐率
	5. 应用：
		5.1 JVM
		5.2 日志 
		5.3 GC频率 
		5.4 调用链
		5.5 慢请求

	
AOP使用场景:
	1. Authentication 权限检查
	2. Caching 缓存 
	3. Context passing 内容传递
	4. Error Handling 错误处理 
	5. Lazy loading 延迟加载
	6. Debugging 调试
	7. logging, tracing, profiling, monitoring 日志记录，跟踪，优化，校准
	8. Performance optimization 性能优化，效率检查
	9. Persistence 持久化
	10. Resource pooling 资源池
	11. Synchronization 同步 
	12. Transaction 事务管理 

Spring Boot Features:
	1. Create stand-alone Spring applications;
	2. Embed Tomcat, Jetty or Undertow directly(no need to deploy WAR files);
	3. Provide opinionated 'starter' dependencies to simplify your build configuration;
	4. Automatically configure Spring and 3rd party libraries whenever possible;
	5. Provide production-ready features such as metrics, health checks and externalized configuration;
	6. Absolutely no code generation and no requirement for XML configuration;
	
Spring Boot除了自动配置，相比传统Spring有什么其他的区别：
	为Spring生态系统的开发提供一种更简洁的方式，提供了很多非功能性特性，例如：嵌入式Servlet容器，Security,统计，健康检查，外部化配置等等，主要体现几点：
	1.Spring Boot可以建立独立的Spring应用程序；
	2.内嵌了如Tomcat，Jetty和Undertow这样的容器，也就是说可以直接跑起来，用不着再做部署工作了；
	3.无需再像Spring那样搞一堆繁琐的xml文件的配置；
	4.可以自动配置Spring。SpringBoot将原有的XML配置改为Java配置，将bean注入改为使用注解注入的方式(@Autowire)，并将多个xml、properties配置浓缩在一个appliaction.yml配置文件中。
	5.提供了一些现有的功能，如量度工具，表单数据验证以及一些外部配置这样的一些第三方功能；
	6.整合常用依赖（开发库，例如spring-webmvc、jackson-json、validation-api和tomcat等），提供的POM可以简化Maven的配置。当我们引入核心依赖时，SpringBoot会自引入其他依赖。

HashMap和Hashtable的区别：
	1. Hashtable是线程安全的，效率比较低;
	2. Hashtable的Key和Value都不能为Null;HashMap的Key和Value都可以为Null;
	3. Hashtable是JDK1.0出现的，HashMap是JDK1.2出现的；
	4. Hashtable默认的初始大小为11，之后每次扩容，容量为原来的2N+1;
	5. HashMap默认的初始大小为16，之后每次扩容，容量为原来的两倍；
	6. Hashtable在计算元素的位置时需要进行取模运算，取模运算比较耗时；
	7. HashMap为了提高计算效率，将哈希表的大小固定为1的幂次，在取模时不需要做除法，只需要位运算，比除法高效很多；
	8. HashMap继承自AbstractMap，而Hashtable继承自Dictionary类。但都同时实现了Map, Cloneable, Serializable三个接口。 

Object的hashCode()方法重写了，equals方法是不是也需要修改？
	不需要。Object类有两个方法equals(),hashCode()，这两个方法都是用来比较两个对象是否相等的，如果两个对象相等(equals)，那么必须拥有相同的hashCode。但两个对象的hashCode相等，并不一定相等(equals)。
	重写equals()方法就必须重写hashCode(),但重写hashCode()不一定重写equals()。

SQL优化的常见方法：
	1. 查询条件不用函数，避免全表扫描；
	2. 减少不必要的表连接；
	3. 有些数据操作的业务逻辑可以放在应用层实现；
	4. 尽量避免使用游标，游标的效率比较差；
	5. 不要把SQL写得太复杂；
	6. 不要循环执行查询；
	7. 用exists代替in;
	8. 表关联不要太多，可以存储部分冗余数据；
	9. 查询尽量用索引；
	10. inner关联的表可以先查出来，再去关联left join的表；
	11. 可以进行表关联数据拆分，即先查出核心数据，再通过核心数据查其他数据，这样会快很多；
	12. 参考SQL执行顺序，进行优化;explain
	13. 使用数据仓库的形式，建立单独的表存储数据，根据时间戳定期更新数据。将多表关联的数据集中抽取到一张表，查询时单表查询，提高了查询效率；
	14. 对查询进行优化，尽量避免全表扫描，首先应考虑在where及order by涉及的列上建立索引；
	15. 尽量避免在where子句中对字段进行null值判断，否则引擎会放弃索引直接全表扫描；用特殊值代替null值；
	16. 尽量避免在where子句中使用!=或<>，否则引擎会放弃索引直接全表扫描；
	17. SQL索引的顺序，字段的顺序；

什么对象会从新生代晋升到老年代：
	1. Eden区满，进行MinorGC，当Eden和Survivor区中仍然存活的对象无法放入到Survivor中，则通过分配担保机制提前转移到老年代中；
	2. 大对象无法在新生代直接分配，会直接在老年代分配；-XX:PretenureSizeThreshold对象的大小大于此值会直接在老年代分配，此参数只对Serial及ParNew有效；
	3. 长期存活的对象进入老年代；-XX:MaxTenuringThreshold，如果对象在Eden出生并在第一次发生MinorGC时仍然存活，并且能够被Survivor中所容纳的话，则该对象会被移动到Survivor中，并且设Age=1；以后每经历一次Minor GC，该对象还存活的话Age=Age+1。
	4. 动态对象年龄判定。JVM并不总是要求对象的年龄达到MaxTenuringThreshold才能晋升到老年代，如果在Survivor区中相同年龄的对象的所有大小之和超过Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无需等到MaxTenuringThreshold中要求的年龄。

ShardingSphere是一套开源的分布式数据库中间件解决方案组成的生态圈，它由Sharding-JDBC、Sharding-Proxy和Sharding-Sidecar（计划中）这3款相互独立的产品组成。 他们均提供标准化的数据分片、分布式事务和数据库治理功能，可适用于如Java同构、异构语言、云原生等各种多样化的应用场景。
ShardingSphere定位为关系型数据库中间件，旨在充分合理地在分布式的场景下利用关系型数据库的计算和存储能力，而并非实现一个全新的关系型数据库。 它与NoSQL和NewSQL是并存而非互斥的关系。NoSQL和NewSQL作为新技术探索的前沿，放眼未来，拥抱变化，是非常值得推荐的。反之，也可以用另一种思路看待问题，放眼未来，关注不变的东西，进而抓住事物本质。 关系型数据库当今依然占有巨大市场，是各个公司核心业务的基石，未来也难于撼动，我们目前阶段更加关注在原有基础上的增量，而非颠覆。

多个数据库连接池的集合，不同数据库连接池属性自适配(DBCP, C3P0, Druid, HikariCP);

两阶段事务提交采用的是X/Open组织所定义的DTP(Distributed Transaction Processing)模型，通过抽象出来的AP,TM,RM的概念可以保证事务的强一致性。其中TM和RM采用XA协议进行双向通信。与传统的本地事务相比，XA事务增加了prepare阶段，数据库除了被动接收提交指令外，还可以反向通知调用方事务是否可以被提交。因此TM可以收集所有分支事务的prepare结果，最后进行原子的提交，保证事务的强一致性。

Java通过定义JTA接口实现了XA的模型，JTA接口里的ResourceManager需要数据库厂商提供XA的驱动实现，而TransactionManager则需要事务管理器的厂商实现，传统的事务管理器需要同应用服务器绑定，因此使用的成本很高。 而嵌入式的事务管器可以以jar包的形式提供服务，同ShardingSphere集成后，可保证分片后跨库事务强一致性。
通常，只有使用了事务管理器厂商所提供的XA事务连接池，才能支持XA事务。ShardingSphere整合XA事务时，分离了XA事务管理和连接池管理，这样接入XA时，可以做到对业务的零侵入。

ShardingSphere的柔性事务已通过第三方SPI实现Saga事务，Saga引擎使用Servicecomb-Saga。

数据库范式：设计关心数据库时，遵从不同的规范要求，设计出合理的关系型数据库，这些不同的规范要求被称为不同的范式，各种范式呈递次规范，越高的范式数据库冗余越小。
目前关系数据库有六种范式：第一范式(1NF)、第二范式(2NF)、第三范式(3NF)、巴斯科德范式(BCNF)、第四范式(4NF)、第五范式(5NF,又称完美范式)。

规范化：一个低一级的关系模式通过模式分解可以转化为若干个高一级范式的关系模式的集合，这个过程叫做规范化。

MongoDB的优点：
	1. 性能优越：快速。在适量级的内存的MongoDB的性能是非常迅速的，它将热数据存储在物理内存中，使得热数据的读写变得十分快。
	2. 高扩展：第三方支持丰富(与其他NoSQL相比，MongoDB也具有的优势)；
	3. 自身的Failover机制；
	4. 弱一致性(最终一致性)，更能保证用户的访问速度；
	5. 文档结构的存储方式，能够更便捷的获取数据：Json存储格式；
	6. 支持大容量的存储，内容GridFS;
	7. 内置Sharding；
MongoDB的缺点：主要是没有事务机制；
	1. MongoDB不支持事务操作(最主要的缺点);
	2. MongoDB占用空间过大；
	3. MongoDB没有如MySQL成熟的维护工具，对于开发和运维是比较大的挑战；
	4. 不支持join操作；不支持group功能，可以通过map-reduce来进行弥补。

MongoDB各个角色的作用：
	1. 配置服务器：是一个独立的mongod进程，保存集群和分片的元数据，即各分片包含了哪些数据的信息。最先开始建立，启用日志功能。像启动普通的mongod一样启动配置服务器，指定configsvr选项。不需要太多的空间和资源，配置服务器的1KB空间相当于真实数据的200MB.保存的只是数据的分布表。当服务不可用，则变成只读，无法分块、迁移数据；
	2. 路由服务器：即mongos，起到一个路由的功能，供程序连接。本身不保存数据，在启动时从配置服务器加载集群信息，开启mongos进程需要配置服务器的地址，指定configdb选项；
	3. 分片服务器：是一个独立的mongod进程，保存数据信息。可以是一个副本集也可以是单独的一台服务器。

分页技术：程序虚拟地址空间产生的地址叫做虚拟地址。这个虚拟地址经过页表的映射后得到程序在内存的真实物理地址。页表作为虚拟地址到页框的映射表，页框是内存的一段地址，是刚好容纳程序一个页面的地址段。当访问页表项的有效位为0时，即内存中不存在需要的页面时，就会发生缺页中断，就需要进行页面置换。
现在讨论MMU中运行机制，先解释TLB，TLB是分页技术中的高速缓存技术，缓存部分页表项，命中率高可以大大提高效率。虚拟地址一开始会被分成两部分，高位为虚拟页号，低位为偏移量。虚拟页号作为关键字在TLB中搜索是否命中页号，如果存在此页号，则可以去除页框号和低位偏移量形成真实物理地址。否则，发生TLB访问失效，此时需要访问内存中的页表，如果页表中存在此页号，则取出页框号。若没有，则发生缺页中断，陷入内核，需要执行磁盘IO，在磁盘中寻找所需页面调入内存。新调入的页面会置换页表和TLB中的一个页面。

内存地址的编号有上限。地址空间的范围和地址总线(Address Bus)的位数直接相关。CPU通过地址总线来向内存说明想要存取数据的地址。以英特尔32位的80386型CPU为例，这款CPU有32个针脚可以传输地址信息。每个针脚对应了一位。如果针脚上是高电压，那么这一位为1.如果是低电压，那么这一位是0。32位的电压高低信息通过地址总线传到内存的32个针脚，内存就能把电压高低信息转化成32位的二进制数，从而知道CPU想要的是哪个位置的数据。用十六进制表示，32位地址空间就是从0x00000000到0xFFFFFFFF。

内存的存储单元采用了随机读取存储器（RAM， Random Access Memory）。所谓的“随机读取”，是指存储器的读取时间和数据所在位置无关。与之相对，很多存储器的读取时间和数据所在位置有关。就拿磁带来说，我们想听其中的一首歌，必须转动带子。如果那首歌是第一首，那么立即就可以播放。如果那首歌恰巧是最后一首，我们快进到可以播放的位置就需要花很长时间。我们已经知道，进程需要调用内存中不同位置的数据。如果数据读取时间和位置相关的话，计算机就很难把控进程的运行时间。因此，随机读取的特性是内存成为主存储器的关键因素。

内存提供的存储空间，除了能满足内核的运行需求，还通常能支持运行中的进程。即使进程所需空间超过内存空间，内存空间也可以通过少量拓展来弥补。换句话说，内存的存储能力，和计算机运行状态的数据总量相当。内存的缺点是不能持久地保存数据。一旦断电，内存中的数据就会消失。因此，计算机即使有了内存这样一个主存储器，还是需要硬盘这样的外部存储器来提供持久的储存空间。

尽管进程和内存的地址非常紧密，但进程并不能直接访问内存。在Linux下，进程不能直接读写内存中地址为0x1位置的数据。进程中能访问的地址，只能是虚拟内存地址(Virtual Memory Address)。操作系统会把虚拟内存地址翻译成真实的内存地址。这种内存管理方式，称为虚拟内存。

每个进程都有自己的一套虚拟内存地址，用来给自己的进程空间编号。进程空间的数据同样以字节为单位，依次增加。从功能上说，虚拟内存地址和物理内存地址类似，都是为数据提供位置索引。进程的虚拟内存地址相互独立。因此，两个进程空间可以有相同的虚拟内存地址，如0x10001000。虚拟内存地址和物理内存地址又有一定的对应关系。对进程某个虚拟内存地址的操作，会被CPU翻译成对某个具体内存地址的操作。

本质上说，虚拟内存地址剥夺了应用程序自由访问物理内存地址的权利。进程对物理内存的访问，必须经过操作系统的审查。因此，掌握着内存对应关系的操作系统，也掌握了应用程序访问内存的闸门。借助虚拟内存地址，操作系统可以保障进程空间的独立性。只要操作系统把两个进程的进程空间对应到不同的内存区域，就让两个进程空间成为“老死不相往来”的两个小王国。两个进程就不可能相互篡改对方的数据，进程出错的可能性就大为减少。

另一方面，有了虚拟内存地址，内存共享也变得简单。操作系统可以把同一物理内存区域对应到多个进程空间。这样，不需要任何的数据复制，多个进程就可以看到相同的数据。内核和共享库的映射，就是通过这种方式进行的。每个进程空间中，最初一部分的虚拟内存地址，都对应到物理内存中预留给内核的空间。这样，所有的进程就可以共享同一套内核空间。共享库的情况也是类似。对于任何一个共享库，计算机只需要往物理内存中加载一次，就可以通过操作对应关系，来让多个进程共同使用。IPO中的共享内存，也有赖于虚拟内存地址。

记录对应关系最简单的办法，就是把对应关系记录在一张表中。为了让翻译速度足够地快，这个表必须加载在内存中。不过，这种记录方式惊人地浪费。如果1GB物理内存的每个字节都有一个对应记录的话，那么光是对应关系就要远远超过内存的空间。由于对应关系的条目众多，搜索到一个对应关系所需的时间也很长。这样的话，会陷入瘫痪。

因此，Linux采用了分页（paging）的方式来记录对应关系。所谓的分页，就是以更大尺寸的单位页（page）来管理内存。在Linux中，通常每页大小为4KB。Linux把物理内存和进程空间都分割成页。

内存分页，可以极大地减少所要记录的内存对应关系。我们已经看到，以字节为单位的对应记录实在太多。如果把物理内存和进程空间的地址都分成页，内核只需要记录页的对应关系，相关的工作量就会大为减少。由于每页的大小是每个字节的4000倍。因此，内存中的总页数只是总字节数的四千分之一。对应关系也缩减为原始策略的四千分之一。分页让虚拟内存地址的设计有了实现的可能。

无论是虚拟页还是物理页，一页之内的地址都是连续的。这样的话，一个虚拟页和一个物理页对应起来，页内的数据就可以按顺序一一对应。这意味着，虚拟内存地址和物理内存地址的末尾部分应该完全相同。大多数情况下，每一页有4096个字节。由于4096是2的12次方，所以地址最后12位的对应关系天然成立。我们把地址的这一部分称为偏移量(offset)。偏移量实际上表达了该字节在页内的位置。地址的前一部分则是页编号。操作系统只需要记录页编号的对应关系。

内存分页制度的关键，在于管理进程空间页和物理页的对应关系。操作系统把对应关系记录在分页表（page table）中。这种对应关系让上层的抽象内存和下层的物理内存分离，从而让Linux能灵活地进行内存管理。由于每个进程会有一套虚拟内存地址，那么每个进程都会有一个分页表。为了保证查询速度，分页表也会保存在内存中。分页表有很多种实现方式，最简单的一种分页表就是把所有的对应关系记录到同一个线性列表中。
这种单一的连续分页表，需要给每一个虚拟页预留一条记录的位置。但对于任何一个应用进程，其进程空间真正用到的地址都相当有限。我们还记得，进程空间会有栈和堆。进程空间为栈和堆的增长预留了地址，但栈和堆很少会占满进程空间。这意味着，如果使用连续分页表，很多条目都没有真正用到。因此，Linux中的分页表，采用了多层的数据结构。多层的分页表能够减少所需的空间。
我们来看一个简化的分页设计，用以说明Linux的多层分页表。我们把地址分为了页编号和偏移量两部分，用单层的分页表记录页编号部分的对应关系。对于多层分页表来说，会进一步分割页编号为两个或更多的部分，然后用两层或更多层的分页表来记录其对应关系。

多层分页表就好像把完整的电话号码分成区号。如果每个区号没有使用，只需要把此区号标记为空即可。同样，一级分页表中0x01记录为空，说明了以0x01开头的虚拟地址段都没有使用。相应的，二级表就不需要存在。正是通过这一手段，多层分页表占据的空间要比单层分页表少了很多。
多层分页表还有一个优势。单层分页表必须存在于连续的内存空间。而多层分页表的二级表，可以散布于内存的不同位置。这样，操作系统就可以利用零碎空间来存储分页表。还需要注意的是，这里简化了分页表的很多细节。最新Linux系统中的分页表多达3层，管理的内存地址也要长很多。不过，多层分页表的基本原理都是相同的。

可以在MongoDB记录中设置任何属性的索引，来实现更快的排序。
如果负载的增加（需要更多的存储空间和更强的处理能力） ，它可以分布在计算机网络中的其他节点上这就是所谓的分片。
Mongo支持丰富的查询表达式。查询指令使用JSON形式的标记，可轻易查询文档中内嵌的对象及数组。
MongoDb 使用update()命令可以实现替换完成的文档（数据）或者一些指定的数据字段 。
Mongodb中的Map/reduce主要是用来对数据进行批量处理和聚合操作。
Map和Reduce。Map函数调用emit(key,value)遍历集合中所有的记录，将key与value传给Reduce函数进行处理。
Map函数和Reduce函数是使用Javascript编写的，并可以通过db.runCommand或mapreduce命令来执行MapReduce操作。
GridFS是MongoDB中的一个内置功能，可以用于存放大量小文件。
MongoDB允许在服务端执行脚本，可以用Javascript编写某个函数，直接在服务端执行，也可以把函数的定义存储在服务端，下次直接调用即可。

MongoDB的优势：
	1. MongoDB适合那些对数据库具体数据格式不明确或者数据库数据格式经常变化的需求模型，而且对开发者十分友好。
	2. MongoDB官方就自带一个分布式文件系统，可以很方便地部署到服务器机群上。MongoDB里有一个Shard的概念，就是方便为了服务器分片使用的。每增加一台Shard，MongoDB的插入性能也会以接近倍数的方式增长，磁盘容量也很可以很方便地扩充。
	3. MongoDB还自带了对map-reduce运算框架的支持，这也很方便进行数据的统计。

用tcpdump输出tcp/ip数据的格式如下：(The general format of a TCP protocol line is:)
src > dst: Flags [tcpflags], seq data-seqno, ack ackno, win window, urg urgent, options [opts], length len 
1. src and dst are the source and destination IP addresses and ports.
2. tcpflags are some combination of S(SYN), F(FIN), P(PUSH), R(RST), U(URG), W(ECN CWR), E(ECN-Echo) or .(ACK), or none if no flags are set.
3. data-seqno describes the portion of sequence space covered by the data in this packet.
4. ackno is sequence number of the next data exptected the other direction on this connection.
5. window is the number of bytes of receive buffer space available the other direction on this connection.
6. urg indicates there is urgent data in the packet.
7. opts are TCP options(e.g., mss 1024).
8. len is the length of payload data.

------------------------------------------------------------------
MongoDB用B树做索引的原因: 
B-树和B+树最重要的一个区别就是：B+树只有叶子节点存放数据，其余节点用来索引，而B-树是每个索引节点都会有Data域。这就决定了B+树更适合用来存储外部数据，也就是所谓的磁盘数据。
从MySQL(InnoDB)的角度来看，B+树是用来充当索引的，一般来说索引非常大，尤其是关系型数据库这种数据量大的索引能达到亿级别，所以为了减少内存的占用，索引也会被存储在磁盘上。
那么MySQL如何衡量查询效率呢？磁盘IO次数，B-树(B类树)的特点就是每层节点数目非常多，层数很少，目的就是为了减少磁盘IO次数，当查询数据的时候，最好的情况就是很快找到目标索引，然后读取数据，使用B+树就能很好的完成这个目的，但是B-树的每个节点都有data域(指针)，这无疑增大了节点大小，即增加了磁盘IO次数(磁盘IO一次读出的数据量大小是固定的，单个数据变大，每次读出的就少，IO次数增多，一次IO非常耗时),而B+树除了叶子节点其他节点并不存储数据，节点小，磁盘IO次数就少。这是优点之一。
另外一个优点：B+树所有的Data域在叶子节点，一般来说都会进行一个优化，就是将所有的叶子节点用指针串起来。这样遍历叶子节点就能获得全部数据，这样就能进行区间访问/遍历了。
数据库采用B树的主要原因是B树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题。正是为了解决这个问题，B+树应运而生。B+树只要遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作(或者效率太低)。
至于MongoDB为什么使用B树而不是B+树，可以从设计角度考虑，它并不是关系型数据库，而是以Json格式作为存储的NoSQL，目的就是高性能、高可用、易扩展。首先它摆脱了关系模型，上面所述的优点二就没那么强烈了，其次MySQL由于使用B+树，数据都在叶子节点上，每次查询都需要访问叶子节点，而MongoDB使用B树，所有节点都有Data域，只要找到指定索引就可以进行访问，无疑单次查询平均快于MySQL。
------------------------------------------------------------------
Consul的可靠性：
Consul是一个服务网格(微服务间的TCP/IP,负责服务之间的网络调用、限流、熔断和监控)解决方案，它是一个分布式的、高度可用的系统，而且开发使用都很简便。它提供了一个功能齐全的控制平面，主要特点是：服务发现、健康检查、键值存储、安全服务通信、多数据中心。

Consul is a service networking solution to connect and secure services across any runtime platform and public or private cloud.
Consul is a service networking tool that allows you to discover services and secure network traffic.

	1. Consul-Kubernetes Deployments: Use Consul service discovery and service mesh features with Kubernetes.
	2. Secure Service Communication: Secure and observe communication between your services without modifying theire code.
	3. Dynamic Load Balanceing: Automate load balancer configuration with Consul and HAProxy, Nginx, or F5.

Consul是一个服务管理软件。支持多数据中心，分布式，高可用的服务发现和配置共享。采用Raft算法，用来保证服务的高可用。
Consul是由HashiCorp基于GO语言开发的支持多数据中心分布式高可用的服务发现和注册服务软件，采用Raft算法保证服务的一致性，且支持健康检查。


